{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332bb46f-95bd-466c-baa8-fa9e37db6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from scipy import stats\n",
    "import numpy as np  \n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e161808d-0fc5-4dfa-a294-6afa85a2b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARFF file has been converted to CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pt/2gvzzpzs05z5fkc59dq42ft40000gn/T/ipykernel_8052/3781024045.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n"
     ]
    }
   ],
   "source": [
    "# Load the ARFF file\n",
    "path = 'bone-marrow.arff'\n",
    "data = arff.loadarff(path)\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Convert byte strings to strings if necessary (common with ARFF files)\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'bone-marrow-converted.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"ARFF file has been converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44524ade-ab54-482e-9603-da2cd3922937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recipientgender Stemcellsource   Donorage Donorage35 IIIV Gendermatch  \\\n",
      "0               1              1  22.830137          0    1           0   \n",
      "1               1              0  23.342466          0    1           0   \n",
      "2               1              0  26.394521          0    1           0   \n",
      "3               0              0  39.684932          1    1           0   \n",
      "4               0              1  33.358904          0    0           0   \n",
      "\n",
      "  DonorABO RecipientABO RecipientRh ABOmatch  ... extcGvHD CD34kgx10d6  \\\n",
      "0        1            1           1        0  ...        1        7.20   \n",
      "1       -1           -1           1        0  ...        1        4.50   \n",
      "2       -1           -1           1        0  ...        1        7.94   \n",
      "3        1            2           1        1  ...        ?        4.25   \n",
      "4        1            2           0        1  ...        1       51.85   \n",
      "\n",
      "    CD3dCD34 CD3dkgx10d8 Rbodymass ANCrecovery PLTrecovery  \\\n",
      "0   1.338760        5.38      35.0        19.0        51.0   \n",
      "1  11.078295        0.41      20.6        16.0        37.0   \n",
      "2  19.013230        0.42      23.4        23.0        20.0   \n",
      "3  29.481647        0.14      50.0        23.0        29.0   \n",
      "4   3.972255       13.05       9.0        14.0        14.0   \n",
      "\n",
      "  time_to_aGvHD_III_IV survival_time survival_status  \n",
      "0                 32.0         999.0             0.0  \n",
      "1            1000000.0         163.0             1.0  \n",
      "2            1000000.0         435.0             1.0  \n",
      "3                 19.0          53.0             1.0  \n",
      "4            1000000.0        2043.0             0.0  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dca22b-8888-412e-aa2a-fd590632d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Donorage  Recipientage  CD34kgx10d6    CD3dCD34  CD3dkgx10d8  \\\n",
      "count  187.000000    187.000000   187.000000  182.000000   182.000000   \n",
      "mean    33.472068      9.931551    11.891781    5.385096     4.745714   \n",
      "std      8.271826      5.305639     9.914386    9.598716     3.859128   \n",
      "min     18.646575      0.600000     0.790000    0.204132     0.040000   \n",
      "25%     27.039726      5.050000     5.350000    1.786683     1.687500   \n",
      "50%     33.550685      9.600000     9.720000    2.734462     4.325000   \n",
      "75%     40.117809     14.050000    15.415000    5.823565     6.785000   \n",
      "max     55.553425     20.200000    57.780000   99.560970    20.020000   \n",
      "\n",
      "        Rbodymass     ANCrecovery     PLTrecovery  time_to_aGvHD_III_IV  \\\n",
      "count  185.000000      187.000000      187.000000            187.000000   \n",
      "mean    35.801081    26752.866310    90937.919786         775408.042781   \n",
      "std     19.650922   161747.200525   288242.407688         418425.252689   \n",
      "min      6.000000        9.000000        9.000000             10.000000   \n",
      "25%     19.000000       13.000000       16.000000        1000000.000000   \n",
      "50%     33.000000       15.000000       21.000000        1000000.000000   \n",
      "75%     50.600000       17.000000       37.000000        1000000.000000   \n",
      "max    103.400000  1000000.000000  1000000.000000        1000000.000000   \n",
      "\n",
      "       survival_time  survival_status  \n",
      "count     187.000000       187.000000  \n",
      "mean      938.743316         0.454545  \n",
      "std       849.589495         0.499266  \n",
      "min         6.000000         0.000000  \n",
      "25%       168.500000         0.000000  \n",
      "50%       676.000000         0.000000  \n",
      "75%      1604.000000         1.000000  \n",
      "max      3364.000000         1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics to get an idea of the data's distribution\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522e53c5-7ac9-4107-8e51-f2538abacad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['Recipientgender', 'Stemcellsource', 'Donorage35', 'IIIV',\n",
      "       'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch',\n",
      "       'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup',\n",
      "       'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen',\n",
      "       'Alel', 'HLAgrI', 'Recipientage10', 'Recipientageint', 'Relapse',\n",
      "       'aGvHDIIIIV', 'extcGvHD'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db04184-e301-4970-bc5f-d25992775da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipientgender: Unique values: ['1' '0']\n",
      "Stemcellsource: Unique values: ['1' '0']\n",
      "Donorage35: Unique values: ['0' '1']\n",
      "IIIV: Unique values: ['1' '0']\n",
      "Gendermatch: Unique values: ['0' '1']\n",
      "DonorABO: Unique values: ['1' '-1' '2' '0']\n",
      "RecipientABO: Unique values: ['1' '-1' '2' '0' '?']\n",
      "RecipientRh: Unique values: ['1' '0' '?']\n",
      "ABOmatch: Unique values: ['0' '1' '?']\n",
      "CMVstatus: Unique values: ['3' '0' '2' '1' '?']\n",
      "DonorCMV: Unique values: ['1' '0' '?']\n",
      "RecipientCMV: Unique values: ['1' '0' '?']\n",
      "Disease: Unique values: ['ALL' 'AML' 'chronic' 'nonmalignant' 'lymphoma']\n",
      "Riskgroup: Unique values: ['1' '0']\n",
      "Txpostrelapse: Unique values: ['0' '1']\n",
      "Diseasegroup: Unique values: ['1' '0']\n",
      "HLAmatch: Unique values: ['0' '1' '3' '2']\n",
      "HLAmismatch: Unique values: ['0' '1']\n",
      "Antigen: Unique values: ['-1' '1' '0' '2' '?']\n",
      "Alel: Unique values: ['-1' '0' '2' '1' '3' '?']\n",
      "HLAgrI: Unique values: ['0' '1' '7' '3' '2' '4' '5']\n",
      "Recipientage10: Unique values: ['0' '1']\n",
      "Recipientageint: Unique values: ['1' '0' '2']\n",
      "Relapse: Unique values: ['0' '1']\n",
      "aGvHDIIIIV: Unique values: ['0' '1']\n",
      "extcGvHD: Unique values: ['1' '?' '0']\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values for these non-numeric (integer-encoded) columns\n",
    "for column in non_numeric_columns:\n",
    "    print(f\"{column}: Unique values: {df[column].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9be8214-a5ad-4a7a-a145-faae4e2d20c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Recipientgender', 'Stemcellsource', 'Donorage', 'Donorage35',\n",
      "       'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch',\n",
      "       'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease', 'Riskgroup',\n",
      "       'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen',\n",
      "       'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint',\n",
      "       'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass',\n",
      "       'survival_status'],\n",
      "      dtype='object')\n",
      "  Recipientgender Stemcellsource   Donorage Donorage35 Gendermatch DonorABO  \\\n",
      "0               1              1  22.830137          0           0        1   \n",
      "1               1              0  23.342466          0           0       -1   \n",
      "2               1              0  26.394521          0           0       -1   \n",
      "3               0              0  39.684932          1           0        1   \n",
      "4               0              1  33.358904          0           0        1   \n",
      "5               1              0  27.391781          0           0        2   \n",
      "6               0              1  34.520548          0           0        0   \n",
      "7               1              0  21.435616          0           0        0   \n",
      "8               1              1  32.641096          0           0        2   \n",
      "9               1              1  28.783562          0           1        1   \n",
      "\n",
      "  RecipientABO RecipientRh ABOmatch CMVstatus  ... Alel HLAgrI Recipientage  \\\n",
      "0            1           1        0         3  ...   -1      0          9.6   \n",
      "1           -1           1        0         0  ...   -1      0          4.0   \n",
      "2           -1           1        0         2  ...   -1      0          6.6   \n",
      "3            2           1        1         1  ...   -1      0         18.1   \n",
      "4            2           0        1         0  ...    0      1          1.3   \n",
      "5            0           1        1         ?  ...   -1      0          8.9   \n",
      "6            1           0        1         ?  ...   -1      0         14.4   \n",
      "7            1           1        1         1  ...    2      7         18.2   \n",
      "8            0           1        1         2  ...   -1      0          7.9   \n",
      "9            0           1        1         2  ...    1      3          4.7   \n",
      "\n",
      "  Recipientage10 Recipientageint CD34kgx10d6   CD3dCD34 CD3dkgx10d8 Rbodymass  \\\n",
      "0              0               1        7.20   1.338760        5.38      35.0   \n",
      "1              0               0        4.50  11.078295        0.41      20.6   \n",
      "2              0               1        7.94  19.013230        0.42      23.4   \n",
      "3              1               2        4.25  29.481647        0.14      50.0   \n",
      "4              0               0       51.85   3.972255       13.05       9.0   \n",
      "5              0               1        3.27   8.412758        0.39      40.0   \n",
      "6              1               2       17.78   2.406248        7.39      51.0   \n",
      "7              1               2        6.41        NaN         NaN      56.0   \n",
      "8              0               1       23.54   3.772555        6.24      20.5   \n",
      "9              0               0        7.69   1.035244        7.43      16.5   \n",
      "\n",
      "  survival_status  \n",
      "0             0.0  \n",
      "1             1.0  \n",
      "2             1.0  \n",
      "3             1.0  \n",
      "4             0.0  \n",
      "5             0.0  \n",
      "6             1.0  \n",
      "7             1.0  \n",
      "8             0.0  \n",
      "9             0.0  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of post-transplant features to exclude\n",
    "post_transplant_features = [\n",
    "    'IIIV', 'aGvHDIIIIV', 'extcGvHD', 'ANCrecovery', 'PLTrecovery', \n",
    "    'time_to_aGvHD_III_IV', 'survival_time', 'Relapse'\n",
    "]\n",
    "\n",
    "# Drop post-transplant features\n",
    "df = df.drop(columns=post_transplant_features)\n",
    "\n",
    "# Check the remaining features\n",
    "print(df.columns)\n",
    "\n",
    "# Example: Display the first few rows of the pre-transplant dataset\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbcb058-9884-4135-8171-084f18a83656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipientgender     0\n",
      "Stemcellsource      0\n",
      "Donorage            0\n",
      "Donorage35          0\n",
      "Gendermatch         0\n",
      "DonorABO            0\n",
      "RecipientABO        1\n",
      "RecipientRh         2\n",
      "ABOmatch            1\n",
      "CMVstatus          16\n",
      "DonorCMV            2\n",
      "RecipientCMV       14\n",
      "Disease             0\n",
      "Riskgroup           0\n",
      "Txpostrelapse       0\n",
      "Diseasegroup        0\n",
      "HLAmatch            0\n",
      "HLAmismatch         0\n",
      "Antigen             1\n",
      "Alel                1\n",
      "HLAgrI              0\n",
      "Recipientage        0\n",
      "Recipientage10      0\n",
      "Recipientageint     0\n",
      "CD34kgx10d6         0\n",
      "CD3dCD34            5\n",
      "CD3dkgx10d8         5\n",
      "Rbodymass           2\n",
      "survival_status     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We also notice that some columns contain '?', which indicates missing data.\n",
    "# We need to decide how to handle these. For simplicity, let's treat them as NaN and then impute.\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Check for missing values after replacing '?' with NaN.\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75cda74-8f8c-4ea8-a94d-8da79804b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for KNN imputation\n",
    "imputation_data = df[['CD34kgx10d6', 'CD3dkgx10d8', 'CD3dCD34']]\n",
    "\n",
    "# Initialize the KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform the imputation\n",
    "imputed_data = knn_imputer.fit_transform(imputation_data)\n",
    "\n",
    "# Assign the imputed values back to the original dataset\n",
    "df[['CD34kgx10d6', 'CD3dkgx10d8', 'CD3dCD34']] = imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43398c46-0f2d-4f10-9d6e-ccc6023f08dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ABOmatch  survival_status RecipientABO DonorABO\n",
      "0         0              0.0            1        1\n",
      "1         0              1.0           -1       -1\n",
      "2         0              1.0           -1       -1\n",
      "3         1              1.0            2        1\n",
      "4         1              0.0            2        1\n",
      "7         1              1.0            1        0\n",
      "8         1              0.0            0        2\n",
      "9         1              0.0            0        1\n",
      "10        1              0.0           -1        0\n",
      "11        0              0.0            1        1\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing 'ABOmatch' values\n",
    "df.dropna(subset=['ABOmatch','Antigen', 'Alel', 'RecipientRh','CMVstatus','RecipientABO', 'DonorABO'], inplace=True)\n",
    "\n",
    "# Display the dataset to check the final state\n",
    "print(df[['ABOmatch', 'survival_status','RecipientABO', 'DonorABO']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e65d06-beab-40f8-b475-c23b3e25434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CMVstatus DonorCMV RecipientCMV  survival_status\n",
      "0          3        1            1              0.0\n",
      "1          0        0            0              1.0\n",
      "2          2        0            1              1.0\n",
      "3          1        1            0              1.0\n",
      "4          0        0            1              0.0\n",
      "7          1        1            0              1.0\n",
      "8          2        0            1              0.0\n",
      "9          2        0            1              0.0\n",
      "10         1        1            0              0.0\n",
      "11         0        0            0              0.0\n"
     ]
    }
   ],
   "source": [
    "# Function to fill CMVstatus, DonorCMV, and RecipientCMV based on the given rules\n",
    "def fill_cmv_status(row):\n",
    "    # Fill CMVstatus\n",
    "    if pd.notna(row['CMVstatus']):\n",
    "        return row['CMVstatus'], row['DonorCMV'], row['RecipientCMV']\n",
    "    \n",
    "    if pd.notna(row['DonorCMV']) and pd.notna(row['RecipientCMV']):\n",
    "        if row['DonorCMV'] == 0 and row['RecipientCMV'] == 0:\n",
    "            return 0, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 1 and row['RecipientCMV'] == 0:\n",
    "            return 1, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 0 and row['RecipientCMV'] == 1:\n",
    "            return 2, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 1 and row['RecipientCMV'] == 1:\n",
    "            return 3, row['DonorCMV'], row['RecipientCMV']\n",
    "    \n",
    "    if pd.isna(row['CMVstatus']):\n",
    "        if row['survival_status'] == 0:\n",
    "            if pd.isna(row['DonorCMV']):\n",
    "                donor_cmv = 1 if row['RecipientCMV'] == 1 else 0\n",
    "                return 1 if row['RecipientCMV'] == 1 else 3, donor_cmv, row['RecipientCMV']\n",
    "            if pd.isna(row['RecipientCMV']):\n",
    "                recipient_cmv = 0 if row['DonorCMV'] == 0 else 1\n",
    "                return 2 if row['DonorCMV'] == 0 else 3, row['DonorCMV'], recipient_cmv\n",
    "        else:\n",
    "            if pd.isna(row['DonorCMV']):\n",
    "                donor_cmv = 0 if row['RecipientCMV'] == 0 else 1\n",
    "                return 0 if row['RecipientCMV'] == 0 else 2, donor_cmv, row['RecipientCMV']\n",
    "            if pd.isna(row['RecipientCMV']):\n",
    "                recipient_cmv = 0 if row['DonorCMV'] == 0 else 1\n",
    "                return 0 if row['DonorCMV'] == 0 else 1, row['DonorCMV'], recipient_cmv\n",
    "    \n",
    "    return row['CMVstatus'], row['DonorCMV'], row['RecipientCMV']\n",
    "\n",
    "# Apply the function to fill missing CMVstatus, DonorCMV, and RecipientCMV values\n",
    "df[['CMVstatus', 'DonorCMV', 'RecipientCMV']] = df.apply(fill_cmv_status, axis=1, result_type='expand')\n",
    "\n",
    "# Display the first few rows of the modified dataset\n",
    "display_data = df[['CMVstatus', 'DonorCMV', 'RecipientCMV', 'survival_status']]\n",
    "print(display_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ffe11d-7302-4c91-8701-438e1a963365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rbodymass  Recipientage\n",
      "0        35.0           9.6\n",
      "1        20.6           4.0\n",
      "2        23.4           6.6\n",
      "3        50.0          18.1\n",
      "4         9.0           1.3\n",
      "7        56.0          18.2\n",
      "8        20.5           7.9\n",
      "9        16.5           4.7\n",
      "10       10.5           1.9\n",
      "11       47.0          13.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate mean body mass for each specific age\n",
    "age_means = df.groupby('Recipientage')['Rbodymass'].mean()\n",
    "\n",
    "# Function to impute missing values with age-specific means\n",
    "def impute_bodymass(row):\n",
    "    if pd.isna(row['Rbodymass']):\n",
    "        return age_means[row['Recipientage']]\n",
    "    else:\n",
    "        return row['Rbodymass']\n",
    "\n",
    "# Apply the imputation function\n",
    "df['Rbodymass'] = df.apply(impute_bodymass, axis=1)\n",
    "\n",
    "\n",
    "# Drop any remaining rows with missing 'Rbodymass' values\n",
    "df.dropna(subset=['Rbodymass'], inplace=True)\n",
    "\n",
    "\n",
    "# Display the dataset to check the imputed values\n",
    "print(df[['Rbodymass', 'Recipientage']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c4ce9c-1dd4-48b7-813a-4c7cd101f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Recipientgender Stemcellsource   Donorage Donorage35 Gendermatch DonorABO  \\\n",
      "0                1              1  22.830137          0           0        1   \n",
      "1                1              0  23.342466          0           0       -1   \n",
      "2                1              0  26.394521          0           0       -1   \n",
      "3                0              0  39.684932          1           0        1   \n",
      "4                0              1  33.358904          0           0        1   \n",
      "7                1              0  21.435616          0           0        0   \n",
      "8                1              1  32.641096          0           0        2   \n",
      "9                1              1  28.783562          0           1        1   \n",
      "10               0              1  29.731507          0           0        0   \n",
      "11               0              1  36.800000          1           0        1   \n",
      "\n",
      "   RecipientABO RecipientRh ABOmatch CMVstatus  ... CD34kgx10d6   CD3dCD34  \\\n",
      "0             1           1        0         3  ...        7.20   1.338760   \n",
      "1            -1           1        0         0  ...        4.50  11.078295   \n",
      "2            -1           1        0         2  ...        7.94  19.013230   \n",
      "3             2           1        1         1  ...        4.25  29.481647   \n",
      "4             2           0        1         0  ...       51.85   3.972255   \n",
      "7             1           1        1         1  ...        6.41   4.832281   \n",
      "8             0           1        1         2  ...       23.54   3.772555   \n",
      "9             0           1        1         2  ...        7.69   1.035244   \n",
      "10           -1           1        1         1  ...       17.66  11.883664   \n",
      "11            1           1        0         0  ...       14.46   2.242442   \n",
      "\n",
      "   CD3dkgx10d8 Rbodymass survival_status Disease_ALL Disease_AML  \\\n",
      "0        5.380      35.0             0.0        True       False   \n",
      "1        0.410      20.6             1.0        True       False   \n",
      "2        0.420      23.4             1.0        True       False   \n",
      "3        0.140      50.0             1.0       False        True   \n",
      "4       13.050       9.0             0.0       False       False   \n",
      "7        3.188      56.0             1.0       False       False   \n",
      "8        6.240      20.5             0.0       False       False   \n",
      "9        7.430      16.5             0.0       False       False   \n",
      "10       1.490      10.5             0.0       False       False   \n",
      "11       6.450      47.0             0.0       False       False   \n",
      "\n",
      "   Disease_chronic Disease_lymphoma Disease_nonmalignant  \n",
      "0            False            False                False  \n",
      "1            False            False                False  \n",
      "2            False            False                False  \n",
      "3            False            False                False  \n",
      "4             True            False                False  \n",
      "7            False            False                 True  \n",
      "8            False            False                 True  \n",
      "9            False            False                 True  \n",
      "10            True            False                False  \n",
      "11            True            False                False  \n",
      "\n",
      "[10 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'Disease' column\n",
    "df = pd.get_dummies(df, columns=['Disease'], drop_first=False)\n",
    "\n",
    "# Display the dataset to check the one-hot encoded 'Disease' column\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ce2659-61ad-4abf-9c13-ed2dd19df1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipientgender         0\n",
      "Stemcellsource          0\n",
      "Donorage                0\n",
      "Donorage35              0\n",
      "Gendermatch             0\n",
      "DonorABO                0\n",
      "RecipientABO            0\n",
      "RecipientRh             0\n",
      "ABOmatch                0\n",
      "CMVstatus               0\n",
      "DonorCMV                0\n",
      "RecipientCMV            0\n",
      "Riskgroup               0\n",
      "Txpostrelapse           0\n",
      "Diseasegroup            0\n",
      "HLAmatch                0\n",
      "HLAmismatch             0\n",
      "Antigen                 0\n",
      "Alel                    0\n",
      "HLAgrI                  0\n",
      "Recipientage            0\n",
      "Recipientage10          0\n",
      "Recipientageint         0\n",
      "CD34kgx10d6             0\n",
      "CD3dCD34                0\n",
      "CD3dkgx10d8             0\n",
      "Rbodymass               0\n",
      "survival_status         0\n",
      "Disease_ALL             0\n",
      "Disease_AML             0\n",
      "Disease_chronic         0\n",
      "Disease_lymphoma        0\n",
      "Disease_nonmalignant    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values after imputing them \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80980a10-a575-4638-9bc5-d003985fe0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'survival_status' is the target variable and it's binary\n",
    "y = df['survival_status']  # target variable\n",
    "X = df.drop('survival_status', axis=1)  # features\n",
    "\n",
    "# Ensure all input features for chi2 are non-negative\n",
    "# Chi-Square input needs to be non-negative. If not, use MinMaxScaler to scale them\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1fcfb1-f592-4cc3-a3a7-bc096569d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature     Score\n",
      "30      Disease_lymphoma  9.109589\n",
      "13         Txpostrelapse  3.002626\n",
      "12             Riskgroup  2.384081\n",
      "21        Recipientage10  1.395818\n",
      "26             Rbodymass  1.081810\n",
      "25           CD3dkgx10d8  0.958306\n",
      "31  Disease_nonmalignant  0.949551\n",
      "23           CD34kgx10d6  0.841769\n",
      "3             Donorage35  0.813180\n",
      "20          Recipientage  0.747882\n",
      "7            RecipientRh  0.673072\n"
     ]
    }
   ],
   "source": [
    "# Apply SelectKBest class to extract top k best features using Chi-Square\n",
    "k = 11  # Number of features to select\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=k)\n",
    "fit = bestfeatures.fit(X, y)\n",
    "\n",
    "# Get the scores for each feature\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# Concatenate the two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Feature', 'Score']  # Naming the dataframe columns\n",
    "print(featureScores.nlargest(k, 'Score'))  # Print k best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1ace3d2-27ea-4311-8d90-df5084085c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting top features \n",
    "features = ['Recipientgender', 'Stemcellsource', 'Donorage', 'Donorage35',\n",
    "       'Gendermatch', 'DonorABO', 'RecipientABO', 'RecipientRh', 'ABOmatch',\n",
    "       'CMVstatus', 'DonorCMV', 'RecipientCMV', 'Disease_lymphoma', 'Riskgroup',\n",
    "       'Txpostrelapse', 'Diseasegroup', 'HLAmatch', 'HLAmismatch', 'Antigen',\n",
    "       'Alel', 'HLAgrI', 'Recipientage', 'Recipientage10', 'Recipientageint',\n",
    "       'CD34kgx10d6', 'CD3dCD34', 'CD3dkgx10d8', 'Rbodymass','Disease_ALL' , 'Disease_AML' , 'Disease_chronic' , 'Disease_nonmalignant' \n",
    "       ]\n",
    "top_features=[ 'Disease_lymphoma', 'Riskgroup',\n",
    "       'Txpostrelapse','Recipientage10'\n",
    "       ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68e2749-6843-4214-9c3c-765bffe0febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for DT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53        19\n",
      "         1.0       0.47      0.60      0.53        15\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.54      0.53      0.53        34\n",
      "\n",
      "Average Training Accuracy for DT: 0.5900\n",
      "Testing Accuracy for DT: 0.5294\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53        19\n",
      "         1.0       0.47      0.60      0.53        15\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.54      0.53      0.53        34\n",
      "\n",
      "Average Training Accuracy for RF: 0.5974\n",
      "Testing Accuracy for RF: 0.5294\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.89      0.74        19\n",
      "         1.0       0.71      0.33      0.45        15\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.67      0.61      0.60        34\n",
      "weighted avg       0.67      0.65      0.61        34\n",
      "\n",
      "Average Training Accuracy for KNN: 0.5903\n",
      "Testing Accuracy for KNN: 0.6471\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for NB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76        19\n",
      "         1.0       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.81      0.60      0.55        34\n",
      "weighted avg       0.78      0.65      0.57        34\n",
      "\n",
      "Average Training Accuracy for NB: 0.5969\n",
      "Testing Accuracy for NB: 0.6471\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53        19\n",
      "         1.0       0.47      0.60      0.53        15\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.54      0.53      0.53        34\n",
      "\n",
      "Average Training Accuracy for SVM: 0.5900\n",
      "Testing Accuracy for SVM: 0.5294\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for ANN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.47      0.53        19\n",
      "         1.0       0.47      0.60      0.53        15\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.54      0.53      0.53        34\n",
      "\n",
      "Average Training Accuracy for ANN: 0.6605\n",
      "Testing Accuracy for ANN: 0.5974\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the data\n",
    "X = df[top_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"ANN\":\n",
    "        # Keras models do not directly support cross_val_score\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "            \n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "        avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "        \n",
    "    else:\n",
    "        train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "        avg_train_accuracy = train_accuracies.mean()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Print accuracies\n",
    "    print(f\"Average Training Accuracy for {name}: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {avg_test_accuracy:.4f}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ac2f2dd-cd2e-4077-8360-2a36e6609ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Riskgroup', 'Txpostrelapse')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Riskgroup', 'Recipientage10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Riskgroup', 'Rbodymass')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Riskgroup', 'CD3dkgx10d8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Riskgroup', 'Disease_nonmalignant')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature set: ('Disease_lymphoma', 'Txpostrelapse', 'Recipientage10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 93\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_set \u001b[38;5;129;01min\u001b[39;00m all_combinations:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating feature set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m     results \u001b[38;5;241m=\u001b[39m evaluate_features(feature_set)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_name, result \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m best_results \u001b[38;5;129;01mor\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m best_results[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[41], line 54\u001b[0m, in \u001b[0;36mevaluate_features\u001b[0;34m(feature_set)\u001b[0m\n\u001b[1;32m     51\u001b[0m y_train_fold, y_val_fold \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(model\u001b[38;5;241m=\u001b[39mcreate_model, model__input_shape\u001b[38;5;241m=\u001b[39mX_train_fold\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_fold, y_train_fold)\n\u001b[1;32m     55\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_train_fold, y_train_fold)\n\u001b[1;32m     56\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    771\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    772\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    773\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    774\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start,\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    776\u001b[0m )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[1;32m    939\u001b[0m     X,\n\u001b[1;32m    940\u001b[0m     y,\n\u001b[1;32m    941\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    942\u001b[0m     warm_start\u001b[38;5;241m=\u001b[39mwarm_start,\n\u001b[1;32m    943\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m    944\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    946\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:312\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    310\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    314\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:645\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 645\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_dataset)\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    648\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[1;32m    649\u001b[0m         ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 744\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m   3479\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "features = [ 'Disease_lymphoma', 'Riskgroup',\n",
    "       'Txpostrelapse','Recipientage10','Rbodymass','CD3dkgx10d8','Disease_nonmalignant'\n",
    "       ]\n",
    "\n",
    "\n",
    "# Define the models\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to evaluate a given set of features\n",
    "def evaluate_features(feature_set):\n",
    "    X = df[list(feature_set)]\n",
    "    y = df['survival_status']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Perform cross-validation on the training set\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"DT\": DecisionTreeClassifier(),\n",
    "        \"RF\": RandomForestClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"NB\": GaussianNB(),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"ANN\": KerasClassifier(model=create_model, model__input_shape=X_train_scaled.shape[1], epochs=100, batch_size=10, verbose=0)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if name == \"ANN\":\n",
    "            # Keras models do not directly support cross_val_score\n",
    "            train_accuracies = []\n",
    "            test_accuracies = []\n",
    "            for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "                X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                model = KerasClassifier(model=create_model, model__input_shape=X_train_fold.shape[1], epochs=100, batch_size=10, verbose=0)\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "                y_val_pred = model.predict(X_val_fold)\n",
    "                test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                test_accuracies.append(test_accuracy)\n",
    "\n",
    "            avg_train_accuracy = np.mean(train_accuracies)\n",
    "            avg_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "        else:\n",
    "            train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "            avg_train_accuracy = train_accuracies.mean()\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        results[name] = {\n",
    "            \"train_accuracy\": avg_train_accuracy,\n",
    "            \"test_accuracy\": avg_test_accuracy,\n",
    "            \"report\": report\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Generate all combinations of features (limiting to 3 to 5 features for manageability)\n",
    "all_combinations = []\n",
    "for r in range(3, 6):\n",
    "    combinations = list(itertools.combinations(features, r))\n",
    "    all_combinations.extend(combinations)\n",
    "\n",
    "best_results = {}\n",
    "\n",
    "# Evaluate each combination\n",
    "for feature_set in all_combinations:\n",
    "    print(f\"Evaluating feature set: {feature_set}\")\n",
    "    results = evaluate_features(feature_set)\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if model_name not in best_results or result['test_accuracy'] > best_results[model_name]['test_accuracy']:\n",
    "            best_results[model_name] = {\n",
    "                \"features\": feature_set,\n",
    "                \"train_accuracy\": result['train_accuracy'],\n",
    "                \"test_accuracy\": result['test_accuracy'],\n",
    "                \"report\": result['report']\n",
    "            }\n",
    "\n",
    "# Print the best results for each model\n",
    "for model_name, result in best_results.items():\n",
    "    print(f\"Best feature set for {model_name}: {result['features']}\")\n",
    "    print(f\"Average Training Accuracy: {result['train_accuracy']:.4f}\")\n",
    "    print(f\"Testing Accuracy: {result['test_accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['report']}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2294913-993d-4a43-97d9-ba51b3b0fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for DT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.32      0.35        19\n",
      "         1.0       0.32      0.40      0.35        15\n",
      "\n",
      "    accuracy                           0.35        34\n",
      "   macro avg       0.36      0.36      0.35        34\n",
      "weighted avg       0.36      0.35      0.35        34\n",
      "\n",
      "Average Training Accuracy for DT: 0.5370\n",
      "Testing Accuracy for DT: 0.3529\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.32      0.34        19\n",
      "         1.0       0.28      0.33      0.30        15\n",
      "\n",
      "    accuracy                           0.32        34\n",
      "   macro avg       0.33      0.32      0.32        34\n",
      "weighted avg       0.33      0.32      0.33        34\n",
      "\n",
      "Average Training Accuracy for RF: 0.5140\n",
      "Testing Accuracy for RF: 0.3235\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.58      0.56        19\n",
      "         1.0       0.43      0.40      0.41        15\n",
      "\n",
      "    accuracy                           0.50        34\n",
      "   macro avg       0.49      0.49      0.49        34\n",
      "weighted avg       0.50      0.50      0.50        34\n",
      "\n",
      "Average Training Accuracy for KNN: 0.6117\n",
      "Testing Accuracy for KNN: 0.5000\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for NB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76        19\n",
      "         1.0       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.81      0.60      0.55        34\n",
      "weighted avg       0.78      0.65      0.57        34\n",
      "\n",
      "Average Training Accuracy for NB: 0.5969\n",
      "Testing Accuracy for NB: 0.6471\n",
      "------------------------------------------------\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.74      0.65        19\n",
      "         1.0       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.56        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.55      0.56      0.54        34\n",
      "\n",
      "Average Training Accuracy for SVM: 0.6718\n",
      "Testing Accuracy for SVM: 0.5588\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for ANN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.74      0.65        19\n",
      "         1.0       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.56        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.55      0.56      0.54        34\n",
      "\n",
      "Average Training Accuracy for ANN: 0.7034\n",
      "Testing Accuracy for ANN: 0.7020\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['Disease_lymphoma', 'Txpostrelapse', 'Recipientage10', 'Rbodymass']\n",
    "\n",
    "# Prepare the data\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=130, batch_size=12, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"ANN\":\n",
    "        # Keras models do not directly support cross_val_score\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "            \n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "        avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "        \n",
    "    else:\n",
    "        train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "        avg_train_accuracy = train_accuracies.mean()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Print accuracies\n",
    "    print(f\"Average Training Accuracy for {name}: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {avg_test_accuracy:.4f}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dc5c6fe-24b0-4bc0-9855-6fdd7355a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best parameters found:  {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Best cross-validation score:  0.6191919191919192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.47      0.49        19\n",
      "         1.0       0.38      0.40      0.39        15\n",
      "\n",
      "    accuracy                           0.44        34\n",
      "   macro avg       0.44      0.44      0.44        34\n",
      "weighted avg       0.44      0.44      0.44        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid with valid options\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7c6a1bd-1922-4752-b61f-1afe07c0d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores with Stacking: [0.62962963 0.62962963 0.66666667 0.74074074 0.65384615]\n",
      "Average cross-validation score with Stacking: 0.6641025641025642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.74      0.65        19\n",
      "         1.0       0.50      0.33      0.40        15\n",
      "\n",
      "    accuracy                           0.56        34\n",
      "   macro avg       0.54      0.54      0.53        34\n",
      "weighted avg       0.55      0.56      0.54        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('svm', SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(stacking_model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "print(f\"Cross-validation scores with Stacking: {scores}\")\n",
    "print(f\"Average cross-validation score with Stacking: {np.mean(scores)}\")\n",
    "\n",
    "# Train the final model\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "y_pred = stacking_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04052e95-7a00-4387-ad31-2ae83747a301",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_column_indices' from 'sklearn.utils' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare the data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, OrdinalEncoder\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     _get_column_indices,\n\u001b[1;32m     20\u001b[0m     _safe_indexing,\n\u001b[1;32m     21\u001b[0m     check_array,\n\u001b[1;32m     22\u001b[0m     check_random_state,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsefuncs_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     csr_mean_variance_axis0,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_features\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_get_column_indices' from 'sklearn.utils' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the SMOTE instance\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__max_depth': [None, 10, 20, 30, 40],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with the pipeline\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_pipeline = random_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024055c-219d-4d31-9566-2c9e1807b903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
