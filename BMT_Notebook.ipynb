{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5d4fe1",
   "metadata": {
    "id": "bc5d4fe1"
   },
   "source": [
    "# Bone Marrow Transplant Children Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a04d25-7e96-4731-b974-f1db49d0171e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Packages Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bb46f-95bd-466c-baa8-fa9e37db6c4f",
   "metadata": {
    "id": "332bb46f-95bd-466c-baa8-fa9e37db6c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score,learning_curve\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab99cf",
   "metadata": {
    "id": "e4ab99cf"
   },
   "source": [
    "# I. Data Preprocessing and Exploratory Data Analysis\n",
    "In this section, we undertake several preprocessing steps to ensure the data is clean, properly formatted, and ready for analysis. These steps are crucial for accurate machine learning predictions and involve transforming the data format, cleaning, encoding categorical variables, and normalizing numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be27925-8327-47e3-8a37-ff2985aa4d89",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92514055",
   "metadata": {
    "id": "92514055",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.1. Format Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on5n8VB624Jv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "on5n8VB624Jv",
    "outputId": "e267836e-d002-4fdd-877c-286e532c4129"
   },
   "outputs": [],
   "source": [
    "# Load the ARFF file\n",
    "path = 'BMT_DATA/bone-marrow.arff'\n",
    "data = arff.loadarff(path)\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Convert byte strings to strings if necessary (common with ARFF files)\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'BMT_DATA/bone-marrow-converted.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"ARFF file has been converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471319ce-70d1-46e8-9d60-732a544ccb52",
   "metadata": {},
   "source": [
    "### 1.2.Previewing Bone Marrow Dataset\n",
    "Before diving into cleaning and transforming the data, we'll get an initial overview of the dataset as it stands after conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd4fe7-c61c-41eb-8813-01ad0991de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b3ab3-a233-4888-8f3f-b05722521e3c",
   "metadata": {},
   "source": [
    "  The first few rows of the bone marrow dataset provide an overview of patient characteristics and medical details. Key features include Recipientgender, Stemcellsource, Donorage, IIIV, Gendermatch, DonorABO, RecipientABO, and survival_status. The dataset contains both numerical and categorical data, with some missing values represented by '?'. The initial data exploration shows a mix of demographic information and clinical measurements,we can notice that the features are divided into two sections:\"Pre-transplant Features\" like:**CD3dCD34** , **Rbodymas**, and \"Post-Transplant Features\" like **time_to_aGvHD_III_IV**,**survival_time** , this requires a detailed analysis on how to choose features in the upcoming sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962a708-c938-4c0d-8f49-dc7628634a5f",
   "metadata": {},
   "source": [
    "### 1.3.Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1e0d-cb88-40f6-b2be-52298649f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics to get an idea of the data's distribution\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e74e3-e3cf-4ee5-8a63-ef0428b1b29f",
   "metadata": {},
   "source": [
    "The summary statistics of the bone marrow dataset provide insights into the distribution of various features. The Donorage ranges from approximately 18 to 56 years, while Recipientage ranges from less than 1 year to 20 years. The CD34kgx10d6 and CD3dkgx10d8 values indicate variability in cell measurements, with CD34kgx10d6 ranging from 0.79 to 57.78 and CD3dkgx10d8 from 0.04 to 20.02. The Rbodymass shows a wide range, from 6.0 to 103.4. Notably, the time_to_aGvHD_III_IV feature has a large number of maximum values, indicating potential censoring or a significant number of patients not experiencing this event. The survival_time varies from 6 to 3364 days, with a mean of 939 days, while the survival_status is roughly balanced, with 45.5% of patients having survived."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb740aa6-9051-408d-bf0e-bfd969fa9cf9",
   "metadata": {},
   "source": [
    "### 1.4. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4db8b3",
   "metadata": {
    "id": "0e4db8b3"
   },
   "source": [
    "In this section, we begin our data cleaning process by identifying any missing or incomplete data points. Understanding where and why data may be missing is crucial for informed imputation and ensuring the robustness of subsequent analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06048c72",
   "metadata": {
    "id": "06048c72"
   },
   "source": [
    "#### 1.4.1 Identifying Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671c52c",
   "metadata": {
    "id": "1671c52c"
   },
   "source": [
    "We must ensure that the DataFrame only contains numeric data. We'll check for non-numeric columns and decide how to handle them â€“ either by encoding them appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e53c5-7ac9-4107-8e51-f2538abacad0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "522e53c5-7ac9-4107-8e51-f2538abacad0",
    "outputId": "654c0cae-b0fa-46b6-f8b8-f8700ee0c5cd"
   },
   "outputs": [],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50394ec",
   "metadata": {
    "id": "b50394ec"
   },
   "source": [
    "##### Check Unique Values of Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db04184-e301-4970-bc5f-d25992775da7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9db04184-e301-4970-bc5f-d25992775da7",
    "outputId": "0a34a359-6220-4e9d-d680-8ff382dc4c95"
   },
   "outputs": [],
   "source": [
    "# Check the unique values for these non-numeric (integer-encoded) columns\n",
    "for column in non_numeric_columns:\n",
    "    print(f\"{column}: Unique values: {df[column].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce21bf0",
   "metadata": {
    "id": "8ce21bf0"
   },
   "source": [
    "#### 1.4.2.Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NKIXNrhPLcMY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKIXNrhPLcMY",
    "outputId": "bf62e5b4-d9c4-48a7-c0ad-89038dfa1835"
   },
   "outputs": [],
   "source": [
    "# We also notice that some columns contain '?', which indicates missing data.\n",
    "# We need to decide how to handle these. For simplicity, let's treat them as NaN and then impute.\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Check for missing values after replacing '?' with NaN.\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56884f26",
   "metadata": {
    "id": "56884f26"
   },
   "source": [
    "The dataset shows several features with missing values after replacing '?' with NaN. The columns CMVstatus and RecipientCMV have the highest number of missing values, with 16 and 14 missing entries, respectively. Other columns like RecipientRh, DonorCMV, CD3dCD34, and CD3dkgx10d8 have a few missing values ranging from 2 to 5. Additionally, columns such as RecipientABO, ABOmatch, Antigen, and Alel have 1 missing value each. Addressing these missing values is crucial for ensuring the integrity and reliability of the predictive models developed from this dataset. Appropriate imputation techniques need to be applied to handle these missing entries effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc462faa",
   "metadata": {
    "id": "dc462faa"
   },
   "source": [
    "##### 1.4.2.1.KNN Imputation/ Dropping Instances for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6c83d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "37c6c83d",
    "outputId": "885138e9-db92-4e8d-8744-519193196541"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for KNN imputation\n",
    "imputation_data = df[['CD34kgx10d6', 'CD3dkgx10d8', 'CD3dCD34']]\n",
    "\n",
    "# Initialize the KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform the imputation\n",
    "imputed_data = knn_imputer.fit_transform(imputation_data)\n",
    "\n",
    "# Assign the imputed values back to the original dataset\n",
    "df[['CD34kgx10d6', 'CD3dkgx10d8', 'CD3dCD34']] = imputed_data# Drop rows with missing 'ABOmatch' values\n",
    "\n",
    "df.dropna(subset=['ABOmatch','Antigen', 'Alel', 'RecipientRh','CMVstatus','RecipientABO', 'DonorABO'], inplace=True)\n",
    "\n",
    "# Display the dataset to check the final state\n",
    "df[['ABOmatch', 'survival_status','RecipientABO', 'DonorABO']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36afacd",
   "metadata": {
    "id": "d36afacd"
   },
   "source": [
    "After dropping rows with missing values in ABOmatch, Antigen, Alel, RecipientRh, CMVstatus, RecipientABO, and DonorABO, the dataset reveals a refined view of the relationship between ABOmatch and survival_status. The cleaned data shows that both matched and unmatched ABO pairs exist among survivors and non-survivors. Specifically, there are instances where an ABO match corresponds with survival, suggesting a potential positive influence, while mismatches do not always correlate with non-survival. This indicates the need for further analysis to determine the exact impact of ABO matching on patient outcomes. Negative values in RecipientABO and DonorABO likely represent special cases or specific blood types, adding another layer to the analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052464b",
   "metadata": {
    "id": "0052464b"
   },
   "source": [
    "##### 1.4.2.2.Filling Missing CMV Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d77f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "449d77f3",
    "outputId": "361f2549-0002-4ba4-b724-bde4a9f2bb7e"
   },
   "outputs": [],
   "source": [
    "# Function to fill CMVstatus, DonorCMV, and RecipientCMV based on the given rules\n",
    "def fill_cmv_status(row):\n",
    "    # Fill CMVstatus\n",
    "    if pd.notna(row['CMVstatus']):\n",
    "        return row['CMVstatus'], row['DonorCMV'], row['RecipientCMV']\n",
    "\n",
    "    if pd.notna(row['DonorCMV']) and pd.notna(row['RecipientCMV']):\n",
    "        if row['DonorCMV'] == 0 and row['RecipientCMV'] == 0:\n",
    "            return 0, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 1 and row['RecipientCMV'] == 0:\n",
    "            return 1, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 0 and row['RecipientCMV'] == 1:\n",
    "            return 2, row['DonorCMV'], row['RecipientCMV']\n",
    "        elif row['DonorCMV'] == 1 and row['RecipientCMV'] == 1:\n",
    "            return 3, row['DonorCMV'], row['RecipientCMV']\n",
    "\n",
    "    if pd.isna(row['CMVstatus']):\n",
    "        if row['survival_status'] == 0:\n",
    "            if pd.isna(row['DonorCMV']):\n",
    "                donor_cmv = 1 if row['RecipientCMV'] == 1 else 0\n",
    "                return 1 if row['RecipientCMV'] == 1 else 3, donor_cmv, row['RecipientCMV']\n",
    "            if pd.isna(row['RecipientCMV']):\n",
    "                recipient_cmv = 0 if row['DonorCMV'] == 0 else 1\n",
    "                return 2 if row['DonorCMV'] == 0 else 3, row['DonorCMV'], recipient_cmv\n",
    "        else:\n",
    "            if pd.isna(row['DonorCMV']):\n",
    "                donor_cmv = 0 if row['RecipientCMV'] == 0 else 1\n",
    "                return 0 if row['RecipientCMV'] == 0 else 2, donor_cmv, row['RecipientCMV']\n",
    "            if pd.isna(row['RecipientCMV']):\n",
    "                recipient_cmv = 0 if row['DonorCMV'] == 0 else 1\n",
    "                return 0 if row['DonorCMV'] == 0 else 1, row['DonorCMV'], recipient_cmv\n",
    "\n",
    "    return row['CMVstatus'], row['DonorCMV'], row['RecipientCMV']\n",
    "\n",
    "# Apply the function to fill missing CMVstatus, DonorCMV, and RecipientCMV values\n",
    "df[['CMVstatus', 'DonorCMV', 'RecipientCMV']] = df.apply(fill_cmv_status, axis=1, result_type='expand')\n",
    "\n",
    "# Display the first few rows of the modified dataset\n",
    "display_data = df[['CMVstatus', 'DonorCMV', 'RecipientCMV', 'survival_status']]\n",
    "display_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e03e8",
   "metadata": {
    "id": "d23e03e8"
   },
   "source": [
    "The dataset, now with filled values for CMVstatus, DonorCMV, and RecipientCMV, reveals interesting patterns regarding patient survival. The CMVstatus column categorizes CMV conditions from 0 to 3, reflecting different donor and recipient CMV combinations. Patients with CMVstatus of 3 (both donor and recipient CMV positive) and 1 (donor positive, recipient negative) are present among both survivors and non-survivors. Similarly, a CMVstatus of 0 (both donor and recipient CMV negative) shows varied survival outcomes. These findings suggest that the CMV status of donors and recipients potentially influences patient survival, indicating the need for further analysis to fully understand these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbf1e3",
   "metadata": {
    "id": "f6dbf1e3"
   },
   "source": [
    "##### 1.4.2.3.Imputation of Body Mass Based on Recipient Age|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274faca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "d274faca",
    "outputId": "9617b99e-8ece-47c6-a911-9d8168aac3b9"
   },
   "outputs": [],
   "source": [
    "# Calculate mean body mass for each specific age\n",
    "age_means = df.groupby('Recipientage')['Rbodymass'].mean()\n",
    "\n",
    "# Function to impute missing values with age-specific means\n",
    "def impute_bodymass(row):\n",
    "    if pd.isna(row['Rbodymass']):\n",
    "        return age_means[row['Recipientage']]\n",
    "    else:\n",
    "        return row['Rbodymass']\n",
    "\n",
    "# Apply the imputation function\n",
    "df['Rbodymass'] = df.apply(impute_bodymass, axis=1)\n",
    "\n",
    "\n",
    "# Drop any remaining rows with missing 'Rbodymass' values\n",
    "df.dropna(subset=['Rbodymass'], inplace=True)\n",
    "\n",
    "\n",
    "# Display the dataset to check the imputed values\n",
    "df[['Rbodymass', 'Recipientage']].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6e70d",
   "metadata": {
    "id": "f1e6e70d"
   },
   "source": [
    "The imputation process for Rbodymass based on Recipientage has successfully filled in missing values with the mean body mass for each specific age group. For example, a recipient aged 9.6 years has an imputed body mass of 35.0, while another aged 18.1 years has a body mass of 50.0. This method ensures that the imputed values are contextually appropriate, reflecting typical body mass values for recipients of similar ages. The dataset now has complete Rbodymass values, improving the quality and reliability of subsequent analyses and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ev1AUcpEbLEq",
   "metadata": {
    "id": "Ev1AUcpEbLEq"
   },
   "source": [
    "##### 1.4.2.4.Imputation of extcGvHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yM9UMce9Z0Uw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "yM9UMce9Z0Uw",
    "outputId": "8b87a86e-5c9e-4778-c36d-bfe5f25b7ffb"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for KNN imputation\n",
    "imputation_data = df[['extcGvHD']]\n",
    "\n",
    "# Initialize the KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform the imputation\n",
    "imputed_data = knn_imputer.fit_transform(imputation_data)\n",
    "\n",
    "# Assign the imputed values back to the original dataset\n",
    "df['extcGvHD'] = imputed_data\n",
    "\n",
    "# Verify if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display the dataset to check the imputed values\n",
    "display_data = df[['extcGvHD']]\n",
    "display_data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xvz8BOmZTnbe",
   "metadata": {
    "id": "Xvz8BOmZTnbe"
   },
   "source": [
    "##### 1.4.2.5.Checking missing values after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7hpSF993LXBu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hpSF993LXBu",
    "outputId": "69328f3f-6f63-4516-e132-4957b4d68fc6"
   },
   "outputs": [],
   "source": [
    "# Check for missing values after replacing '?' with NaN.\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d06e4a",
   "metadata": {
    "id": "78d06e4a"
   },
   "source": [
    "The results show that there are no remaining missing values in any of the columns, indicating that the imputation and data cleaning processes were successful. The dataset is now complete and ready for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ru-XSgWyMFZ2",
   "metadata": {
    "id": "Ru-XSgWyMFZ2"
   },
   "source": [
    "#### 1.4.3. Conversion of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c05c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40c05c16",
    "outputId": "bb96b561-473d-4f25-e4df-d92ecf14c5f4"
   },
   "outputs": [],
   "source": [
    "# List to keep track of columns converted\n",
    "converted_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype in ['float64', 'int64']:  # Check if the column is float or int\n",
    "        unique_values = df[column].dropna().unique()  # Get unique values excluding NaN\n",
    "        # Check if the unique values in the column are only 0.0 and 1.0\n",
    "        if set(unique_values).issubset({0.0, 1.0}):\n",
    "            df[column] = df[column].astype(bool)\n",
    "            converted_columns.append(column)\n",
    "\n",
    "print(f\"Converted columns to boolean: {converted_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KqNho7_gMOGW",
   "metadata": {
    "id": "KqNho7_gMOGW"
   },
   "source": [
    "#### 1.4.3. One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0905ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "be0905ef",
    "outputId": "886f0493-0c40-4cde-e561-23f902e3d845"
   },
   "outputs": [],
   "source": [
    "# One-hot encode the 'Disease' column\n",
    "df = pd.get_dummies(df, columns=['Disease'], drop_first=True)\n",
    "\n",
    "# Display the dataset to check the one-hot encoded 'Disease' column\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3aa74",
   "metadata": {
    "id": "0de3aa74"
   },
   "source": [
    "#### 1.4.4.Recoding Placeholder Values\n",
    "Address placeholder values used in place of missing data, such as the 1000000.0 in 'time_to_aGvHD_III_IV'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rNjJamiFwTFy",
   "metadata": {
    "id": "rNjJamiFwTFy"
   },
   "outputs": [],
   "source": [
    "# Recode placeholder values to a more appropriate representation\n",
    "df['time_to_aGvHD_III_IV'] = df['time_to_aGvHD_III_IV'].replace(1000000.0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801baec",
   "metadata": {
    "id": "d801baec"
   },
   "source": [
    "#### 1.4.5.Normalizing/Scaling Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a2780",
   "metadata": {
    "id": "880a2780"
   },
   "source": [
    "To ensure that all features contribute equally to the analysis, we normalize the data. This process involves scaling numerical values to a common scale without distorting differences in the ranges of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e40c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "8a1e40c9",
    "outputId": "e948afc6-7dd8-4737-bd71-6250d1d9481f"
   },
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame after previous cleaning steps.\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select only the numeric columns from the dataframe\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Scale these numeric columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Display the first few rows of the scaled data to confirm the process\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf498a",
   "metadata": {
    "id": "6ecf498a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa53a1",
   "metadata": {
    "id": "2cfa53a1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1.Visualisations of the Impact of numerical predictors on target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ef8ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "703ef8ce",
    "outputId": "29549707-2007-4797-8cf2-66daf439abe0"
   },
   "outputs": [],
   "source": [
    "# Check the data types to confirm they're appropriate for the plotting functions\n",
    "df.dtypes\n",
    "\n",
    "# Identify numeric and binary columns; adjust this list based on your specific dataset\n",
    "numeric_predictors = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Create boxplots for each numeric predictor grouped by survival status\n",
    "for predictor in numeric_predictors:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Boxplot can handle 0/1 binary data as categories\n",
    "    sns.boxplot(x='survival_status', y=predictor, data=df)\n",
    "    plt.title(f'Impact of {predictor} on Survival Status')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3223b",
   "metadata": {
    "id": "dec3223b"
   },
   "source": [
    " The boxplots illustrate the impact of various numeric predictors on survival status:\n",
    "Impact of Donorage on Survival Status:\n",
    "The distributions of Donorage are similar for both survival statuses, with slight differences in medians and ranges.\n",
    "Impact of Rbodymass on Survival Status:\n",
    "The median Rbodymass for survivors is slightly higher, but the ranges overlap significantly between the two groups.\n",
    "Impact of CD3dCD34 on Survival Status:\n",
    "The values for CD3dCD34 are generally low, with some outliers, and no significant difference between the survival statuses.\n",
    "Impact of Recipientage on Survival Status:\n",
    "The boxplots for Recipientage show similar medians and ranges for both survival statuses, indicating no strong impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151054c",
   "metadata": {
    "id": "7151054c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2.Visualisations of the Impact of Boolean predictors on target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c865359",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0c865359",
    "outputId": "163a08ef-1526-43d8-a46c-ed60e0f06092"
   },
   "outputs": [],
   "source": [
    "# Identify binary predictors and ensure they are converted to string for plotting\n",
    "binary_predictors = [col for col in df.columns if df[col].dropna().unique().size == 2]\n",
    "\n",
    "for predictor in binary_predictors:\n",
    "    if df[predictor].dtype == 'bool':\n",
    "        df[predictor] = df[predictor].astype(str)  # Convert boolean columns to string\n",
    "\n",
    "# Now plotting\n",
    "for predictor in binary_predictors:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=predictor, hue='survival_status', data=df)\n",
    "    plt.title(f'Distribution of {predictor} by Survival Status')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b1738",
   "metadata": {
    "id": "768b1738"
   },
   "source": [
    "The bar plots illustrate the distribution of various binary predictors by survival status. For the diseases (e.g., AML, chronic, lymphoma, nonmalignant), there is a noticeable difference in the survival distributions, indicating these diseases potentially impact survival outcomes. The distributions of predictors like Relapse, aGvHDIIIIV, HLAmismatch, Recipientage10, and Txpostrelapse also show variations between survival statuses, highlighting their significance in survival analysis. Variables such as ABOmatch, Riskgroup, Gendermatch, and RecipientRh similarly display distinct survival patterns, suggesting these factors are important in determining survival outcomes. These visualizations help in identifying which binary predictors are significantly associated with survival status.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189400d4",
   "metadata": {
    "id": "189400d4"
   },
   "source": [
    "### 2.3. Correlation heatmap (full-feature dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e55c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "492e55c0",
    "outputId": "969ed585-997a-4703-a49d-124d415a9bb4"
   },
   "outputs": [],
   "source": [
    "# Identify and convert boolean string columns to numeric (0 and 1)\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':  # Check for object type columns\n",
    "        unique_values = df[column].dropna().unique()\n",
    "        if set(unique_values) <= {'True', 'False'}:\n",
    "            df[column] = df[column].map({'True': 1, 'False': 0}).astype(int)\n",
    "\n",
    "# Check data types and conversion results\n",
    "print(df.dtypes)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1314d",
   "metadata": {
    "id": "98b1314d"
   },
   "source": [
    "The correlation matrix heatmap provides a visual representation of the relationships between different variables. The color intensity indicates the strength and direction of the correlations, with red representing strong positive correlations and blue representing strong negative correlations. For instance, HLA mismatch and HLA match show a strong positive correlation, while body mass index (Rbodymass) and CD3/CD34 counts (CD3dCD34) exhibit a moderate positive correlation. The matrix helps identify multicollinearity and potential interactions between variables, which are critical for feature selection and model building in predictive analytics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42cb390-bd97-4016-a724-2204427c98e6",
   "metadata": {
    "id": "2be43547",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# II.Adopting TWO Approaches\n",
    "In our study, we employ two distinct approaches to predict patient survival post-transplantation. The first approach utilizes the full range of available features, encompassing both pre- and post-transplant variables. This comprehensive method aims to capture the complete landscape of factors influencing survival, providing a detailed understanding of the patterns and relationships in the data. By leveraging the full feature set, we seek to identify the most significant predictors and evaluate various machine learning models for their performance. The second approach, in contrast, focuses solely on pre-transplant features. This strategy is motivated by the practical need to make early predictions when post-transplant data is not yet available. By reducing the feature set, we aim to mitigate overfitting issues and improve model generalization, particularly given the limited dataset size. Both approaches are designed to complement each other, offering insights into the critical factors affecting survival and refining predictive capabilities for different stages of the transplantation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5e9b3-747b-4ca5-ab62-73419277aa7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. First Approach\n",
    "The first approach leverages the full range of available features, including both pre- and post-transplant variables, to predict patient survival. This comprehensive method allows us to capture the complete spectrum of factors influencing survival outcomes. By utilizing all features, we aim to understand the intricate relationships and identify the most significant predictors of survival. This approach serves to evaluate the performance of various machine learning models, providing a benchmark for predictive accuracy and insight into the factors that most impact post-transplant survival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f73a6",
   "metadata": {
    "id": "b75f73a6"
   },
   "source": [
    "### 1.1.Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0c73",
   "metadata": {
    "id": "e81b0c73"
   },
   "outputs": [],
   "source": [
    "# Assume 'survival_status' is the target variable and it's binary\n",
    "X = df.drop('survival_status', axis=1)  # features\n",
    "y = df['survival_status']  # target variable\n",
    "\n",
    "# Encode the target variable if it's not numeric\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Ensure all input features for chi2 are non-negative\n",
    "# Chi-Square input needs to be non-negative. If not, use MinMaxScaler to scale them\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a6a23",
   "metadata": {
    "id": "b82a6a23"
   },
   "source": [
    "We designated survival_status as the target variable and encoded it to ensure it was numeric. All input features were scaled using MinMaxScaler to ensure non-negative values, a requirement for the Chi-Square test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5da16f",
   "metadata": {
    "id": "5c5da16f"
   },
   "source": [
    "#### 1.1.2. Selecting Features Using Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06a8cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f06a8cb",
    "outputId": "f77739da-d464-4762-dd88-cb42e1f58158"
   },
   "outputs": [],
   "source": [
    "# Apply SelectKBest class to extract top k best features using Chi-Square\n",
    "k = 11  # Number of features to select\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=k)\n",
    "fit = bestfeatures.fit(X, y)\n",
    "\n",
    "# Get the scores for each feature\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# Concatenate the two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Feature', 'Score']  # Naming the dataframe columns\n",
    "print(featureScores.nlargest(k, 'Score'))  # Print k best features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d7fd74",
   "metadata": {
    "id": "25d7fd74"
   },
   "source": [
    "Using the Chi-Square test, we identified the top 11 features most strongly associated with bone marrow survival outcomes. The highest-scoring feature was survival_time with a score of 21.77, indicating its significant impact on predicting survival status. Other notable features included PLTrecovery (15.61), Relapse (14.73), and Disease_lymphoma (9.10), highlighting their crucial roles in survival prediction. Additionally, features such as ANCrecovery, Riskgroup, Recipientage10, Txpostrelapse, CD3dkgx10d8, Rbodymass, and Donorage35 were selected, each contributing to the model's predictive power. This selection process ensures that the most relevant features are used, improving the accuracy and efficiency of the predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c33988",
   "metadata": {
    "id": "96c33988"
   },
   "source": [
    "##### Visualizing the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da61e60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "6da61e60",
    "outputId": "0a40562a-bc7b-46e5-efb6-dac6381a1285"
   },
   "outputs": [],
   "source": [
    "# Plotting the scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Score', y='Feature', data=featureScores.sort_values(by=\"Score\", ascending=False))\n",
    "plt.title('Feature Importance based on Chi-Square Test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530ff08",
   "metadata": {
    "id": "f530ff08"
   },
   "source": [
    "The bar plot displays the importance of features in predicting bone marrow survival outcomes, as determined by the Chi-Square test. The top features, including survival_time, PLTrecovery, Relapse, and Disease_lymphoma, show the highest scores, indicating their significant impact on survival prediction. These features are followed by ANCrecovery, Riskgroup, and Recipientage10, among others. The visualization clearly highlights the relative importance of each feature, guiding the selection of the most relevant variables for building an effective predictive model. The inclusion of these key features is expected to enhance the model's accuracy and robustness in predicting survival outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f6db6",
   "metadata": {
    "id": "2a7f6db6"
   },
   "source": [
    "#### 1.1.3.Correlation heatmap (reduced feature dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3c199",
   "metadata": {
    "id": "b5c3c199"
   },
   "outputs": [],
   "source": [
    "# Add 'survival_status' to the list of top features for correlation analysis\n",
    "top_features = featureScores.nlargest(11, 'Score')['Feature'].tolist() + ['survival_status']\n",
    "\n",
    "# Isolate these features in your DataFrame\n",
    "selected_features_df = df[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85234a48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "85234a48",
    "outputId": "474b02d6-f071-4f8c-f033-f7b8352540d4"
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix for the selected features\n",
    "correlation_matrix = selected_features_df.corr()\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix of Top 11 Features')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e85b7",
   "metadata": {
    "id": "542e85b7"
   },
   "source": [
    "**Observations from the Correlation Matrix of Top Features with Survival Status**\n",
    "This correlation matrix provides a visual representation of how closely related the selected features are to each other and to the survival status. Here are some notable insights:\n",
    "\n",
    "**Strong Negative Correlation**: There is a notably strong negative correlation between survival_time and survival_status, indicating that longer survival times are associated with a positive outcome. This relationship is intuitive and expected in survival analysis.\n",
    "Potential Predictive Features: Features like PLTrecovery and ANCrecovery show moderate correlations with the survival status, suggesting that recovery metrics play a significant role in outcomes. These features could be key predictors in our predictive models.\n",
    "\n",
    "**Low Correlation with Survival Status**: Some features, such as Disease_lymphoma and Donorage35, show relatively low correlation with the survival status, which might suggest that they have less direct impact on the outcome, although they could still be contributing to the model in combination with other features.\n",
    "\n",
    "**Inter-feature Relationships**: The heatmap reveals some strong relationships between features themselves. For instance, Txpostrelapse and Relapse show a strong correlation, which might indicate redundancy or a strong relationship that could be explored for feature engineering purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c06ad",
   "metadata": {
    "id": "ca0c06ad",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2.Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f2b49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "849f2b49",
    "outputId": "7f677d5f-55e7-4792-db0b-317b95828532"
   },
   "outputs": [],
   "source": [
    "#  Prepare the data\n",
    "X = df.drop('survival_status', axis=1)\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Train the models and evaluate\n",
    "results = []\n",
    "accuracy_results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "    else:\n",
    "        roc_auc = roc_auc_score(y_test, model.decision_function(X_test_scaled))\n",
    "\n",
    "    train_accuracy = model.score(X_train_scaled, y_train)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"ROC_AUC\": roc_auc\n",
    "    })\n",
    "    accuracy_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "print(results_df)\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a8d71",
   "metadata": {
    "id": "315a8d71"
   },
   "source": [
    "The evaluation of various machine learning models on the dataset revealed significant insights into their performance. The Decision Tree (DT) model achieved perfect scores on both the training and testing sets, indicating potential overfitting. The Random Forest (RF) model also performed exceptionally well, with a test accuracy of 0.97, high precision, recall, and ROC AUC scores, making it a reliable model for this task. The Artificial Neural Network (ANN) demonstrated robust performance with a test accuracy of 0.94, balanced precision, recall, and F1 scores, indicating good generalization. The Support Vector Machine (SVM) model showed moderate performance with a test accuracy of 0.79, high precision, but lower recall. The Naive Bayes (NB) model achieved a test accuracy of 0.71, with higher precision but lower recall, indicating some trade-offs in model performance. The K-Nearest Neighbors (KNN) model had the lowest performance with a test accuracy of 0.65, highlighting its limitations in this context. Overall, the Random Forest model emerged as the most accurate and stable, while the ANN also showed promising results, making these models strong candidates for predicting survival status in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8zgzcnsP5gCo",
   "metadata": {
    "id": "8zgzcnsP5gCo"
   },
   "source": [
    "#### Repeated cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edb177-aea8-4981-b74d-717dd8602cdb",
   "metadata": {},
   "source": [
    "In this section, we aim at rechoosing Features using Repeated cross Validation for more accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mNTOMmoB5kHV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mNTOMmoB5kHV",
    "outputId": "b451857c-4dee-4607-bf2d-6a429366f79f"
   },
   "outputs": [],
   "source": [
    "# Best parameters from the grid search\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 'log2',\n",
    "    'max_depth': 30,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "\n",
    "# Initialize the model with best parameters\n",
    "rf_best = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Perform repeated cross-validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "cv_scores = cross_val_score(rf_best, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"Repeated cross-validation scores: {cv_scores}\")\n",
    "print(f\"Average cross-validation score: {cv_scores.mean()} Â± {cv_scores.std()}\")\n",
    "\n",
    "# Train the final model with the best parameters on the full training set\n",
    "rf_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = rf_best.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = rf_best.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arDwnziKDmLC",
   "metadata": {
    "id": "arDwnziKDmLC"
   },
   "source": [
    "The repeated cross-validation scores indicate that the model is performing well on average, with an average cross-validation score of approximately 0.927 Â± 0.043. The classification report on the test set shows perfect precision, recall, and F1-scores for both classes, which could be a sign of overfitting, especially given the small dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nPi_A_Wa5kJ9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778
    },
    "id": "nPi_A_Wa5kJ9",
    "outputId": "28dcf687-768a-45b5-f05c-9f3762251cc0"
   },
   "outputs": [],
   "source": [
    "# Use only the top features\n",
    "top_features = ['survival_time', 'extcGvHD', 'Relapse', 'Rbodymass', 'CD34kgx10d6', 'CD3dkgx10d8', 'Recipientage']\n",
    "\n",
    "# Prepare the data with selected features\n",
    "X = df[top_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the RandomForest model with best parameters\n",
    "rf_best = RandomForestClassifier(**best_params)\n",
    "rf_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf_best.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-validated AUC score\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "roc_auc_scores = cross_val_score(rf_best, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"Cross-validated AUC scores: {roc_auc_scores}\")\n",
    "print(f\"Average AUC score: {roc_auc_scores.mean():.4f} Â± {roc_auc_scores.std():.4f}\")\n",
    "\n",
    "# Compute ROC curve on the test set\n",
    "y_test_prob = rf_best.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "print(f\"Test ROC AUC score: {roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wO9SDRqxEaO1",
   "metadata": {
    "id": "wO9SDRqxEaO1"
   },
   "source": [
    "The results indicate an excellent performance of the Random Forest model, with perfect scores in accuracy, precision, recall, and F1-score on the test set. The cross-validated AUC scores are also very high, indicating strong predictive performance across different folds. The ROC curve further confirms the model's robustness, achieving an area under the curve (AUC) of 1.0 on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8d5d1-f781-4712-b22f-4270abff8207",
   "metadata": {},
   "source": [
    "### 1.3.Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N2aHrCx5FbJb",
   "metadata": {
    "id": "N2aHrCx5FbJb"
   },
   "source": [
    "#### 1.3.1.Displaying accuracy of each model after repeated cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skKhEaQsFaEJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skKhEaQsFaEJ",
    "outputId": "9e50b5f1-6ec9-4f44-e42d-b3353eab1460"
   },
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform repeated cross-validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"ANN\":\n",
    "        scores = []\n",
    "        for train_index, test_index in cv.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_test_fold = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "            y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            scores.append(model.score(X_test_fold, y_test_fold))\n",
    "        results[name] = scores\n",
    "    else:\n",
    "        scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "        results[name] = scores\n",
    "\n",
    "# Print the cross-validation accuracy for each model\n",
    "for name, scores in results.items():\n",
    "    print(f\"{name} accuracy: {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rsd2_0upKLhg",
   "metadata": {
    "id": "rsd2_0upKLhg"
   },
   "source": [
    "Overall, the Random Forest model stands out as the most accurate and stable model, making it a strong candidate for predicting the survival status in this dataset. The Artificial Neural Network also shows promising results with high accuracy and reasonable stability. On the other hand, the K-Nearest Neighbors model appears to be the least reliable with the lowest accuracy and the highest variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p6sdxGtB5E91",
   "metadata": {
    "id": "p6sdxGtB5E91"
   },
   "source": [
    "#### 1.3.2.ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9457e75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "a9457e75",
    "outputId": "a36acb84-10ef-409b-e446-ef08f69310d0"
   },
   "outputs": [],
   "source": [
    "# Train models and calculate ROC AUC\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "\n",
    "# Plot chance level\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance (area = 0.50)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0fb90c",
   "metadata": {
    "id": "1d0fb90c"
   },
   "source": [
    " The ROC curve comparison plot for various models, including Decision Tree (DT), Random Forest (RF), K-Nearest Neighbors (KNN), Naive Bayes (NB), Support Vector Machine (SVM), and Artificial Neural Network (ANN), shows the following:\n",
    "\n",
    "**ROC AUC Scores:**\n",
    "\n",
    "DT, RF, and ANN have perfect ROC AUC scores of 1.00, indicating perfect classification performance with no false positives or false negatives.\n",
    "SVM has a high ROC AUC score of 0.99, indicating excellent performance.\n",
    "KNN and NB have lower ROC AUC scores of 0.96, indicating very good but not perfect performance.\n",
    "Model Performance:\n",
    "\n",
    "The Decision Tree (DT), Random Forest (RF), and Artificial Neural Network (ANN) models exhibit the highest performance, perfectly distinguishing between the two classes.\n",
    "The Support Vector Machine (SVM) also shows very high performance, closely approaching perfect classification.\n",
    "K-Nearest Neighbors (KNN) and Naive Bayes (NB) have slightly lower but still strong performance compared to the top-performing models.\n",
    "\n",
    "**Model Selection:**\n",
    "Given the perfect performance of DT, RF, and ANN, these models might be preferred for this specific dataset.\n",
    "The high performance of SVM also makes it a strong candidate for classification tasks.\n",
    "KNN and NB, while slightly less effective, still provide robust classification capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CK09qQqmJMlV",
   "metadata": {
    "id": "CK09qQqmJMlV"
   },
   "source": [
    "#### 1.3.3.Training vs Testing Accuracy for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2fdb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "2bd2fdb2",
    "outputId": "65f69b7b-36b4-4e2f-d583-10b72992eca1"
   },
   "outputs": [],
   "source": [
    "# Convert dictionary to list of dictionaries for plotting\n",
    "accuracy_results = [\n",
    "    {\"Model\": name, \"Accuracy\": np.mean(scores), \"StdDev\": np.std(scores)}\n",
    "    for name, scores in results.items()\n",
    "]\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "accuracy_df.set_index('Model').plot(kind='bar', y='Accuracy', yerr='StdDev', ax=ax, capsize=4)\n",
    "ax.set_title('Model Accuracy Comparison (Repeated Cross-Validation)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.grid(True)\n",
    "plt.legend(title='Metrics')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3b3af",
   "metadata": {
    "id": "a0e3b3af"
   },
   "source": [
    "The bar plot titled \"Model Accuracy Comparison (Repeated Cross-Validation)\" displays the average accuracy of various machine learning models with error bars representing the standard deviation of accuracy scores obtained from repeated cross-validation. The models include Decision Trees (DT), Random Forests (RF), K-Nearest Neighbors (KNN), Naive Bayes (NB), Support Vector Machines (SVM), and Artificial Neural Networks (ANN). Random Forest (RF) achieved the highest average accuracy, followed closely by the Artificial Neural Network (ANN) and Support Vector Machine (SVM) models. K-Nearest Neighbors (KNN) had the lowest average accuracy with the highest variability, indicating less consistent performance across different cross-validation splits. The error bars provide a visual indication of the reliability of each model's performance, with smaller bars suggesting more consistent accuracy across folds. Overall, the plot highlights the robustness and performance of each model, aiding in the selection of the most appropriate algorithm for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NmTzu679JXtU",
   "metadata": {
    "id": "NmTzu679JXtU"
   },
   "source": [
    "#### 1.3.4.ANN Training vs. Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af952d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "6af952d6",
    "outputId": "50fa47d3-9653-4c44-86bd-a284d87243ee"
   },
   "outputs": [],
   "source": [
    "# Train the model with validation and capture the history\n",
    "model = create_model()\n",
    "history = model.fit(X_train_scaled, y_train, epochs=120, batch_size=10, verbose=0, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Check the keys to ensure metrics are being recorded\n",
    "print(\"Keys in history object:\", history.history.keys())\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('ANN Training vs. Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0bafd",
   "metadata": {
    "id": "c6d0bafd"
   },
   "source": [
    "the plot \"ANN Training vs. Validation Accuracy\" shows the performance of the Artificial Neural Network (ANN) model over 120 epochs. Here are some observations:\n",
    "\n",
    "Initial Learning Phase: Both training and validation accuracy start low, around 40%, and rapidly increase within the first 20 epochs. This indicates that the model is quickly learning from the data.\n",
    "\n",
    "Convergence: After about 20 epochs, the training and validation accuracy curves start to stabilize. Both accuracies remain high and relatively close to each other, which suggests that the model is learning well without significant overfitting or underfitting.\n",
    "\n",
    "Validation Accuracy Fluctuations: There are minor fluctuations in the validation accuracy throughout the training process. These fluctuations are normal and indicate how the model performs on unseen data. The validation accuracy consistently remains high, around 95% to 100%, which is a positive sign.\n",
    "\n",
    "Final Accuracy: By the end of 120 epochs, both training and validation accuracy are approximately equal, indicating a well-trained model with good generalization capability.\n",
    "\n",
    "This plot demonstrates that the ANN model is performing well on this dataset, with both training and validation accuracies reaching high values and stabilizing, which is a desirable outcome in model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bb4d7-1401-4dd1-bced-7101a6d58a9c",
   "metadata": {},
   "source": [
    "#### 1.3.5. Model Selection\n",
    "We will be choosing the best model ensuring a **high recall**, which means most true survivors are identified, allowing for necessary interventions, and **high precision**, which ensures those identified as survivors are truly likely to survive, balancing the overall effectiveness of the model.\n",
    "\n",
    "### Model Performance Metrics\n",
    "\n",
    "**Random Forest (RF):**\n",
    "* Precision (Class 0/1): 1.00 / 1.00\n",
    "* Recall (Class 0/1): 1.00 / 1.00\n",
    "* F1-Score (Class 0/1): 1.00 / 1.00\n",
    "* Accuracy: 1.00\n",
    "* Cross-validated AUC score: 0.9732 Â± 0.0259\n",
    "* Test ROC AUC score: 1.0000\n",
    "* Repeated cross-validation accuracy: 0.9319 Â± 0.0446\n",
    "\n",
    "**Artificial Neural Network (ANN):**\n",
    "* Precision (Class 0/1): 0.86 / 0.92\n",
    "* Recall (Class 0/1): 0.95 / 0.80\n",
    "* F1-Score (Class 0/1): 0.90 / 0.86\n",
    "* Accuracy: 0.88\n",
    "* Repeated cross-validation accuracy: 0.9086 Â± 0.0594\n",
    "\n",
    "**Support Vector Machine (SVM):**\n",
    "* Precision (Class 0/1): 0.75 / 0.90\n",
    "* Recall (Class 0/1): 0.95 / 0.60\n",
    "* F1-Score (Class 0/1): 0.84 / 0.72\n",
    "* Accuracy: 0.79\n",
    "* Repeated cross-validation accuracy: 0.9004 Â± 0.0573\n",
    "\n",
    "**Naive Bayes (NB):**\n",
    "* Precision (Class 0/1): 0.67 / 0.86\n",
    "* Recall (Class 0/1): 0.95 / 0.40\n",
    "* F1-Score (Class 0/1): 0.78 / 0.55\n",
    "* Accuracy: 0.71\n",
    "* Repeated cross-validation accuracy: 0.8938 Â± 0.0572\n",
    "\n",
    "**K-Nearest Neighbors (KNN):**\n",
    "* Precision (Class 0/1): 0.64 / 0.67\n",
    "* Recall (Class 0/1): 0.84 / 0.40\n",
    "* F1-Score (Class 0/1): 0.73 / 0.50\n",
    "* Accuracy: 0.65\n",
    "* Repeated cross-validation accuracy: 0.8274 Â± 0.0750\n",
    "\n",
    "**Decision Tree (DT):**\n",
    "* Precision (Class 0/1): 1.00 / 1.00\n",
    "* Recall (Class 0/1): 1.00 / 1.00\n",
    "* F1-Score (Class 0/1): 1.00 / 1.00\n",
    "* Accuracy: 1.00\n",
    "* Repeated cross-validation accuracy: 0.8954 Â± 0.0477\n",
    "\n",
    "### Observations\n",
    "\n",
    "**Random Forest (RF):**\n",
    "* High Recall (Class 0/1): 1.00 / 1.00\n",
    "* High Precision (Class 0/1): 1.00 / 1.00\n",
    "* Balanced F1-Score: 1.00 for both classes\n",
    "* High repeated cross-validation accuracy: 0.9319 Â± 0.0446\n",
    "\n",
    "**Artificial Neural Network (ANN):**\n",
    "* High Recall (Class 0): 0.95\n",
    "* High Precision (Class 1): 0.92\n",
    "* Balanced F1-Score: 0.90 / 0.86\n",
    "* High repeated cross-validation accuracy: 0.9086 Â± 0.0594\n",
    "\n",
    "**Support Vector Machine (SVM):**\n",
    "* High Recall (Class 0): 0.95\n",
    "* High Precision (Class 1): 0.90\n",
    "* Balanced F1-Score: 0.84 / 0.72\n",
    "* High repeated cross-validation accuracy: 0.9004 Â± 0.0573\n",
    "\n",
    "**Naive Bayes (NB):**\n",
    "* High Recall (Class 0): 0.95\n",
    "* High Precision (Class 1): 0.86\n",
    "* Balanced F1-Score: 0.78 / 0.55\n",
    "* Moderate repeated cross-validation accuracy: 0.8938 Â± 0.0572\n",
    "\n",
    "**K-Nearest Neighbors (KNN):**\n",
    "* High Recall (Class 0): 0.84\n",
    "* High Precision (Class 1): 0.67\n",
    "* Balanced F1-Score: 0.73 / 0.50\n",
    "* Low repeated cross-validation accuracy: 0.8274 Â± 0.0750\n",
    "\n",
    "**Decision Tree (DT):**\n",
    "* High Recall (Class 0/1): 1.00 / 1.00\n",
    "* High Precision (Class 0/1): 1.00 / 1.00\n",
    "* Balanced F1-Score: 1.00 for both classes\n",
    "* Moderate repeated cross-validation accuracy: 0.8954 Â± 0.0477\n",
    "\n",
    "### Best Model Selection\n",
    "\n",
    "Considering both precision and recall:\n",
    "* Random Forest (RF) shows the best balance of precision and recall across both classes, with perfect F1-scores of 1.00 for both classes. It also has the highest repeated cross-validation accuracy of 0.9319 Â± 0.0446.\n",
    "* Artificial Neural Network (ANN) performs well with balanced precision and recall, making it a strong candidate, with a repeated cross-validation accuracy of 0.9086 Â± 0.0594.\n",
    "* Support Vector Machine (SVM) and Naive Bayes (NB) provide high precision and recall but slightly lower than RF and ANN.\n",
    "* K-Nearest Neighbors (KNN) has the lowest performance with the highest variability, indicating less consistent performance.\n",
    "* Decision Tree (DT) performs perfectly in terms of precision, recall, and F1-score but might indicate overfitting, with moderate cross-validation accuracy.\n",
    "\n",
    "### Conclusion\n",
    "**Random Forest (RF)** is the best model based on the analysis of precision and recall. It provides the highest balanced F1-scores and robust performance across both classes, making it the most reliable model for predicting survival status in this context. The high cross-validated AUC scores and consistent performance further validate its effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5717604",
   "metadata": {
    "id": "c5717604"
   },
   "source": [
    "### 1.4. Conclusion about the first approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092428cc",
   "metadata": {
    "id": "092428cc"
   },
   "source": [
    "Our objective was to evaluate the Bone Marrow Transplant (BMT) process using various machine learning models to predict survival status. We used models such as Decision Trees (DT), Random Forests (RF), K-Nearest Neighbors (KNN), Naive Bayes (NB), Support Vector Machines (SVM), and Artificial Neural Networks (ANN). The models were assessed based on accuracy, precision, recall, F1-score, and ROC-AUC.\n",
    "\n",
    "The DT model achieved perfect scores, indicating overfitting. RF performed exceptionally well with high test accuracies, followed by ANN with robust performance. SVM showed high precision but lower recall, NB had moderate results, and KNN had the lowest performance.\n",
    "\n",
    "Repeated cross-validation showed that models performed well on average, with RF standing out as the most accurate and stable. ANN also showed high accuracy and stability.\n",
    "\n",
    "This approach highlighted the importance of using comprehensive features, tuning hyperparameters, and managing class imbalance for reliable predictive performance in medical applications. RF was identified as the most reliable model for predicting survival status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87298868",
   "metadata": {
    "id": "87298868",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Second Approach\n",
    "The second approach focuses on pre-transplant features to predict patient survival. This strategy addresses practical scenarios where only early-stage data is available, aiming to provide timely predictions before post-transplant information is accessible. By reducing the feature set to pre-transplant variables, we aim to enhance model generalization and reduce overfitting, especially given the limited number of instances. This approach is essential for early intervention and planning, offering a streamlined and practical predictive model for real-world clinical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a7901",
   "metadata": {
    "id": "cc0a7901",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1. Excluding Post-Transplant Features(second approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be8214-a5ad-4a7a-a145-faae4e2d20c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "c9be8214-a5ad-4a7a-a145-faae4e2d20c5",
    "outputId": "d994fb77-c0d2-4786-f365-7f55d27e7207"
   },
   "outputs": [],
   "source": [
    "# List of post-transplant features to exclude\n",
    "post_transplant_features = [\n",
    "    'IIIV', 'aGvHDIIIIV', 'extcGvHD', 'ANCrecovery', 'PLTrecovery',\n",
    "    'time_to_aGvHD_III_IV', 'survival_time', 'Relapse'\n",
    "]\n",
    "\n",
    "# Drop post-transplant features\n",
    "df = df.drop(columns=post_transplant_features)\n",
    "\n",
    "# Check the remaining features\n",
    "df.columns\n",
    "\n",
    "# Example: Display the first few rows of the pre-transplant dataset\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3ac01",
   "metadata": {
    "id": "54b3ac01",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80980a10-a575-4638-9bc5-d003985fe0dc",
   "metadata": {
    "id": "80980a10-a575-4638-9bc5-d003985fe0dc"
   },
   "outputs": [],
   "source": [
    "# Assume 'survival_status' is the target variable and it's binary\n",
    "X = df.drop('survival_status', axis=1)  # features\n",
    "y = df['survival_status']  # target variable\n",
    "\n",
    "# Encode the target variable if it's not numeric\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Ensure all input features for chi2 are non-negative\n",
    "# Chi-Square input needs to be non-negative. If not, use MinMaxScaler to scale them\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb873d6",
   "metadata": {
    "id": "4eb873d6"
   },
   "source": [
    "#### 2.2.1. Selecting Features Using Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fcfb1-f592-4cc3-a3a7-bc096569d41e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b1fcfb1-f592-4cc3-a3a7-bc096569d41e",
    "outputId": "249d3654-b63c-48c5-888e-cd9b27704069"
   },
   "outputs": [],
   "source": [
    "# Apply SelectKBest class to extract top k best features using Chi-Square\n",
    "k = 11  # Number of features to select\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=k)\n",
    "fit = bestfeatures.fit(X, y)\n",
    "\n",
    "# Get the scores for each feature\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "# Concatenate the two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Feature', 'Score']  # Naming the dataframe columns\n",
    "print(featureScores.nlargest(k, 'Score'))  # Print k best features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ddbc0",
   "metadata": {
    "id": "667ddbc0"
   },
   "source": [
    "The Chi-Square test has identified the top 11 features that significantly influence the survival status of bone marrow patients. The feature Disease_lymphoma has the highest score (9.109589), indicating a strong association with survival outcomes. Txpostrelapse and Riskgroup also show substantial influence, suggesting that post-relapse transplants and risk group classifications are critical factors. Other notable features include Recipientage10 and Rbodymass, reflecting the importance of age and body mass in survival predictions. The presence of specific cell count measurements (CD3dkgx10d8 and CD34kgx10d6), along with factors like donor age (Donorage35) and blood type compatibility (RecipientRh), further highlight the multifaceted nature of survival determinants. These findings will guide the development of a robust predictive model by focusing on the most relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c42ec",
   "metadata": {
    "id": "d71c42ec"
   },
   "source": [
    "##### Visualizing the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0877b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "ae0877b2",
    "outputId": "df72e126-9805-44c9-e0f9-030fbc035089"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the scores\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Score', y='Feature', data=featureScores.sort_values(by=\"Score\", ascending=False))\n",
    "plt.title('Feature Importance based on Chi-Square Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b9367",
   "metadata": {
    "id": "831b9367"
   },
   "source": [
    "Based on the provided Chi-Square feature importance plot, the top features impacting survival status are:\n",
    "Disease_lymphoma: This feature is identified as the most significant, indicating a strong correlation with the survival status.\n",
    "Txpostrelapse: Post-relapse treatment appears to be highly influential in determining survival, highlighting the critical role of treatment response.\n",
    "Riskgroup: The classification of patients into risk groups significantly affects survival outcomes, underscoring the importance of initial risk assessment.\n",
    "Recipientage10: Age of the recipient, particularly in the context of a 10-year interval, is a notable factor, which may be linked to the general health and recovery potential of younger vs. older patients.\n",
    "Rbodymass: Recipient's body mass also shows a considerable impact, suggesting that physical health and body composition are important for survival.\n",
    "Disease_nonmalignant: Nonmalignant diseases are important predictors, indicating different survival probabilities compared to malignant conditions.\n",
    "Donorage35: The age of the donor, especially around the 35-year mark, influences survival, possibly due to factors related to donor health and compatibility.\n",
    "Recipientage: General age of the recipient is a significant factor, reaffirming the role of age in survival rates.\n",
    "RecipientRh: The Rh factor of the recipient has a measurable effect on survival, possibly related to blood compatibility issues.\n",
    "Stemcellsource: The source of stem cells used in treatment impacts survival, pointing to the importance of selecting the appropriate stem cell source.\n",
    "ABOmatch: Blood type compatibility (ABO match) between donor and recipient is a crucial factor, emphasizing the importance of matching for successful outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afd0bd",
   "metadata": {
    "id": "93afd0bd"
   },
   "source": [
    "#### 2.2.2.Correlation heatmap (reduced feature dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6ac3b",
   "metadata": {
    "id": "0ba6ac3b"
   },
   "outputs": [],
   "source": [
    "# Add 'survival_status' to the list of top features for correlation analysis\n",
    "top_features = featureScores.nlargest(11, 'Score')['Feature'].tolist() + ['survival_status']\n",
    "\n",
    "# Isolate these features in your DataFrame\n",
    "selected_features_df = df[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f3cea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "745f3cea",
    "outputId": "5eaa7266-57c5-4b72-c28e-f474f1132c6d"
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix for the selected features\n",
    "correlation_matrix = selected_features_df.corr()\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix of Top 11 Features')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f16411",
   "metadata": {
    "id": "a0f16411"
   },
   "source": [
    "The correlation matrix of the top features indicates several key insights:\n",
    "Disease_lymphoma has a positive correlation of 0.24 with survival_status, suggesting that the presence of lymphoma is associated with higher survival rates.\n",
    "Txpostrelapse and Riskgroup are moderately correlated with survival_status, with correlations of 0.14 and 0.15 respectively. This implies that post-relapse treatments and the initial risk group classification have a significant impact on survival outcomes.\n",
    "Recipientage10 shows a notable positive correlation (0.22) with survival_status, indicating that the age group of the recipient at the time of transplantation plays a crucial role in the survival rate.\n",
    "Rbodymass has the highest correlation with survival_status among the body metrics, at 0.22. This suggests that body mass is an important factor to consider when predicting survival outcomes.\n",
    "Disease_nonmalignant shows a slight negative correlation (-0.08) with survival_status, which may imply that nonmalignant diseases slightly reduce the likelihood of survival compared to malignant conditions.\n",
    "There are significant correlations among some features themselves, such as between Recipientage10 and Rbodymass (0.80), indicating that younger recipients tend to have higher body mass.\n",
    "These observations underscore the importance of these medically relevant features in predicting outcomes for pediatric bone marrow transplantation, providing valuable insights that can enhance predictive models and ultimately improve patient care.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ea664",
   "metadata": {
    "id": "895ea664",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZtI8A63khRNJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtI8A63khRNJ",
    "outputId": "1f06073b-c9f7-4152-ba24-019728620a11"
   },
   "outputs": [],
   "source": [
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Edz23HlRhW2n",
   "metadata": {
    "id": "Edz23HlRhW2n"
   },
   "source": [
    "Initially, we will select the top 7 features based on their chi-square significance and their medical relevance. These features are:\n",
    "- `Disease_lymphoma`\n",
    "- `Riskgroup`\n",
    "- `Txpostrelapse`\n",
    "- `Recipientage10`\n",
    "- `Rbodymass`\n",
    "- `CD3dkgx10d8`\n",
    "- `Disease_nonmalignant`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BS9HGMDIhYx0",
   "metadata": {
    "id": "BS9HGMDIhYx0"
   },
   "outputs": [],
   "source": [
    "top_7_features=[ 'Disease_lymphoma', 'Riskgroup',\n",
    "       'Txpostrelapse','Recipientage10','Rbodymass','CD3dkgx10d8','Disease_nonmalignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e2749-6843-4214-9c3c-765bffe0febb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f68e2749-6843-4214-9c3c-765bffe0febb",
    "outputId": "ee1ab40f-2643-44b0-c262-97ad5d6164eb"
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df[top_7_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"ANN\":\n",
    "        # Keras models do not directly support cross_val_score\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "        avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    else:\n",
    "        train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "        avg_train_accuracy = train_accuracies.mean()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(report)\n",
    "\n",
    "    # Print accuracies\n",
    "    print(f\"Average Training Accuracy for {name}: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {avg_test_accuracy:.4f}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858d7f2",
   "metadata": {
    "id": "b858d7f2"
   },
   "source": [
    "#### 2.3.1. Model Evaluation with Top 7 Features\n",
    "\n",
    "\n",
    "Using these top 7 features, we trained various models including Decision Trees (DT), Random Forests (RF), K-Nearest Neighbors (KNN), Naive Bayes (NB), Support Vector Machines (SVM), and Artificial Neural Networks (ANN). However, the results were not satisfactory, indicating potential overfitting due to the small dataset size (~180 samples).\n",
    "\n",
    "To address this, we decided to reduce the number of features and explore combinations of 3 to 5 features. This approach aims to improve model performance and reduce overfitting by identifying the most effective feature subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sNJas-TDiLsY",
   "metadata": {
    "id": "sNJas-TDiLsY"
   },
   "source": [
    "#### 2.3.2. Choosing the best combination for features for a good model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ozgevNiMeV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "26ozgevNiMeV",
    "outputId": "9b91c0c0-0273-4fc5-a865-750ff608198b"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "features = [ 'Disease_lymphoma', 'Riskgroup',\n",
    "       'Txpostrelapse','Recipientage10','Rbodymass','CD3dkgx10d8','Disease_nonmalignant'\n",
    "       ]\n",
    "\n",
    "\n",
    "# Define the models\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to evaluate a given set of features\n",
    "def evaluate_features(feature_set):\n",
    "    X = df[list(feature_set)]\n",
    "    y = df['survival_status']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Perform cross-validation on the training set\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"DT\": DecisionTreeClassifier(),\n",
    "        \"RF\": RandomForestClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"NB\": GaussianNB(),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"ANN\": KerasClassifier(model=create_model, model__input_shape=X_train_scaled.shape[1], epochs=100, batch_size=10, verbose=0)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name == \"ANN\":\n",
    "            # Keras models do not directly support cross_val_score\n",
    "            train_accuracies = []\n",
    "            test_accuracies = []\n",
    "            for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "                X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                model = KerasClassifier(model=create_model, model__input_shape=X_train_fold.shape[1], epochs=100, batch_size=10, verbose=0)\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "                y_val_pred = model.predict(X_val_fold)\n",
    "                test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                test_accuracies.append(test_accuracy)\n",
    "\n",
    "            avg_train_accuracy = np.mean(train_accuracies)\n",
    "            avg_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "        else:\n",
    "            train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "            avg_train_accuracy = train_accuracies.mean()\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        results[name] = {\n",
    "            \"train_accuracy\": avg_train_accuracy,\n",
    "            \"test_accuracy\": avg_test_accuracy,\n",
    "            \"report\": report\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Generate all combinations of features (limiting to 3 to 5 features for manageability)\n",
    "all_combinations = []\n",
    "for r in range(3, 6):\n",
    "    combinations = list(itertools.combinations(features, r))\n",
    "    all_combinations.extend(combinations)\n",
    "\n",
    "best_results = {}\n",
    "\n",
    "# Evaluate each combination\n",
    "for feature_set in all_combinations:\n",
    "    print(f\"Evaluating feature set: {feature_set}\")\n",
    "    results = evaluate_features(feature_set)\n",
    "\n",
    "    for model_name, result in results.items():\n",
    "        if model_name not in best_results or result['test_accuracy'] > best_results[model_name]['test_accuracy']:\n",
    "            best_results[model_name] = {\n",
    "                \"features\": feature_set,\n",
    "                \"train_accuracy\": result['train_accuracy'],\n",
    "                \"test_accuracy\": result['test_accuracy'],\n",
    "                \"report\": result['report']\n",
    "            }\n",
    "\n",
    "# Print the best results for each model\n",
    "for model_name, result in best_results.items():\n",
    "    print(f\"Best feature set for {model_name}: {result['features']}\")\n",
    "    print(f\"Average Training Accuracy: {result['train_accuracy']:.4f}\")\n",
    "    print(f\"Testing Accuracy: {result['test_accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{result['report']}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_cq9WvMNnBhG",
   "metadata": {
    "id": "_cq9WvMNnBhG"
   },
   "source": [
    "**Choice on Best Feature Combination**:\n",
    "['Disease_lymphoma', 'Txpostrelapse', 'Riskgroup','Recipientage10']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UQ7GlO_3nE2s",
   "metadata": {
    "id": "UQ7GlO_3nE2s"
   },
   "source": [
    "#### 2.3.3. Retraining Models With a Reduced Features Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6wrP1Q2fnHDm",
   "metadata": {
    "id": "6wrP1Q2fnHDm",
    "outputId": "efaa28b4-ec30-4825-ea74-b3335c6c5665"
   },
   "outputs": [],
   "source": [
    "best_combi_features = ['Disease_lymphoma', 'Txpostrelapse', 'Riskgroup','Recipientage10']\n",
    "\n",
    "# Prepare the data\n",
    "X = df[best_combi_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"ANN\":\n",
    "        # Keras models do not directly support cross_val_score\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "        avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    else:\n",
    "        train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "        avg_train_accuracy = train_accuracies.mean()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(report)\n",
    "\n",
    "    # Print accuracies\n",
    "    print(f\"Average Training Accuracy for {name}: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {avg_test_accuracy:.4f}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SURtjDjNnJkB",
   "metadata": {
    "id": "SURtjDjNnJkB"
   },
   "source": [
    "Feature Reduction Benefits: KNN and SVM showed improved generalization with fewer features, suggesting that feature reduction helped in these cases.\n",
    "\n",
    "Feature Reduction Drawbacks: DT, RF, and ANN showed decreased performance, indicating that they might benefit from a richer feature set.\n",
    "\n",
    "Stability: NB's performance remained stable, suggesting it is less sensitive to the number of features.\n",
    "\n",
    "These observations highlight the importance of balancing feature selection and model complexity, especially with small datasets. While reducing features can help some models generalize better, others may require more features to capture the underlying patterns effectively.\n",
    "\n",
    "\n",
    "Overall, even though some accuracies decreased with the reduced feature set, the primary goal was to address overfitting. By reducing the number of features, we achieved better generalization in some models. The KNN and SVM models, in particular, showed improved test accuracy, indicating that the reduced feature set helped mitigate overfitting. This approach is overall better as it promotes a balance between model complexity and generalization, which is crucial, especially with a small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fH4KNRqPnMGB",
   "metadata": {
    "id": "fH4KNRqPnMGB"
   },
   "source": [
    "#### 2.3.4.Enhancing Models Perormance :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l9A5tJk4nRjh",
   "metadata": {
    "id": "l9A5tJk4nRjh"
   },
   "source": [
    "##### **SVM - KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AiIGKc6UnTUG",
   "metadata": {
    "id": "AiIGKc6UnTUG",
    "outputId": "22fc06a8-122d-42fd-a78d-52a2189a9c05"
   },
   "outputs": [],
   "source": [
    "# Function to handle class imbalance using resampling\n",
    "def balance_classes(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    majority_class = df[y.name].value_counts().idxmax()\n",
    "    minority_class = df[y.name].value_counts().idxmin()\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = df[df[y.name] == majority_class]\n",
    "    df_minority = df[df[y.name] == minority_class]\n",
    "\n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    X_upsampled = df_upsampled.drop(columns=y.name)\n",
    "    y_upsampled = df_upsampled[y.name]\n",
    "\n",
    "    return X_upsampled, y_upsampled\n",
    "\n",
    "# Selected features\n",
    "selected_features = ['Disease_lymphoma', 'Txpostrelapse', 'Rbodymass']\n",
    "\n",
    "# Prepare the data\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Handle class imbalance\n",
    "X_balanced, y_balanced = balance_classes(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "### SVM Model\n",
    "# Define the parameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Perform Randomized Search for SVM\n",
    "random_search_svm = RandomizedSearchCV(estimator=svm, param_distributions=svm_param_grid, n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found for SVM: \", random_search_svm.best_params_)\n",
    "print(\"Best cross-validation score for SVM: \", random_search_svm.best_score_)\n",
    "\n",
    "# Evaluate the best SVM model on the train and test set\n",
    "best_svm = random_search_svm.best_estimator_\n",
    "y_svm_train_pred = best_svm.predict(X_train_scaled)\n",
    "y_svm_test_pred = best_svm.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification Report for SVM (Test):\")\n",
    "print(classification_report(y_test, y_svm_test_pred))\n",
    "print(f\"Test Accuracy for SVM: {accuracy_score(y_test, y_svm_test_pred):.4f}\")\n",
    "print(\"------------------------------------------------\\n\")\n",
    "\n",
    "### KNN Model\n",
    "# Define the parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform Randomized Search for KNN\n",
    "random_search_knn = RandomizedSearchCV(estimator=knn, param_distributions=knn_param_grid, n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found for KNN: \", random_search_knn.best_params_)\n",
    "print(\"Best cross-validation score for KNN: \", random_search_knn.best_score_)\n",
    "\n",
    "# Evaluate the best KNN model on the train and test set\n",
    "best_knn = random_search_knn.best_estimator_\n",
    "y_knn_train_pred = best_knn.predict(X_train_scaled)\n",
    "y_knn_test_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(\"Classification Report for KNN (Test):\")\n",
    "print(classification_report(y_test, y_knn_test_pred))\n",
    "print(f\"Test Accuracy for KNN: {accuracy_score(y_test, y_knn_test_pred):.4f}\")\n",
    "print(\"------------------------------------------------\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c13f4-78f6-4432-919b-a7ddcc5bf4d1",
   "metadata": {
    "id": "931c13f4-78f6-4432-919b-a7ddcc5bf4d1"
   },
   "source": [
    "The hyperparameter tuning results indicate that the Random Forest (RF) model, with its best parameters, achieved the highest cross-validation score of 0.6514 and a test accuracy of 0.6316, outperforming both the Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) models. The SVM, with a linear kernel and a cross-validation score of 0.6123, reached a test accuracy of 0.5789, showing balanced but lower performance compared to RF. The KNN model, optimized with distance weighting and seven neighbors, had a cross-validation score of 0.6248 and a test accuracy of 0.6053, suggesting moderate performance. While RF demonstrated the best generalization and balanced metrics between precision and recall, KNN exhibited signs of overfitting due to high training accuracy but lower test accuracy. The correlation matrix of the selected features supports their relevance, though further refinement or additional features might enhance model performance. Overall, RF's robustness and consistent accuracy make it the most reliable model for predicting survival status in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f074f-ddbb-417c-a38f-83652af0d0fb",
   "metadata": {
    "id": "7e6f074f-ddbb-417c-a38f-83652af0d0fb"
   },
   "source": [
    "##### **Artificial Neural Network**\n",
    "Previous Results Showed that it is best to add more features to ann for increasing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b40f4-23b5-4bef-8395-e00271df9cd9",
   "metadata": {
    "id": "e75b40f4-23b5-4bef-8395-e00271df9cd9",
    "outputId": "f3b8fc66-60dd-4637-a202-c44067193db6"
   },
   "outputs": [],
   "source": [
    "selected_features = ['Disease_lymphoma', 'Txpostrelapse', 'Recipientage10', 'Rbodymass','Riskgroup']\n",
    "\n",
    "# Prepare the data\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "ann_model = {\n",
    "    \"ANN\": KerasClassifier(build_fn=create_model, epochs=120, batch_size=10, verbose=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in ann_model.items():\n",
    "    if name == \"ANN\":\n",
    "        # Keras models do not directly support cross_val_score\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        for train_index, val_index in skf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_accuracy = model.score(X_train_fold, y_train_fold)\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            test_accuracy = accuracy_score(y_val_fold, (y_val_pred > 0.5).astype(int))\n",
    "\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "        avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "        avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    else:\n",
    "        train_accuracies = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='accuracy')\n",
    "        avg_train_accuracy = train_accuracies.mean()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        avg_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(report)\n",
    "\n",
    "    # Print accuracies\n",
    "    print(f\"Average Training Accuracy for {name}: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy for {name}: {avg_test_accuracy:.4f}\")\n",
    "    print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e992f-501e-47c7-901f-d912cd5da7e1",
   "metadata": {
    "id": "9b7e992f-501e-47c7-901f-d912cd5da7e1"
   },
   "source": [
    "The Artificial Neural Network (ANN) model, trained on the selected features, demonstrates an average training accuracy of 0.7463 and a testing accuracy of 0.6964. The classification report for the test set indicates that the model achieves a balanced precision and recall for both classes, with an overall accuracy of 0.53. The results show moderate performance and slight overfitting, as indicated by the discrepancy between training and testing accuracies. The ANN's ability to maintain a relatively high training accuracy suggests that the model is learning the patterns in the training data well but struggles to generalize to unseen data. This underscores the need for further tuning or potentially adding more features to improve generalization and reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c6403-8399-4c07-a8ed-9d9e718e5699",
   "metadata": {
    "id": "436c6403-8399-4c07-a8ed-9d9e718e5699"
   },
   "source": [
    "##### **RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68363f93-6c2c-462b-8776-41f8532f245f",
   "metadata": {
    "id": "68363f93-6c2c-462b-8776-41f8532f245f",
    "outputId": "abd988ce-039f-4d19-c62a-e9c4e1732f64"
   },
   "outputs": [],
   "source": [
    "# Function to handle class imbalance using resampling\n",
    "def balance_classes(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    majority_class = df[y.name].value_counts().idxmax()\n",
    "    minority_class = df[y.name].value_counts().idxmin()\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = df[df[y.name] == majority_class]\n",
    "    df_minority = df[df[y.name] == minority_class]\n",
    "\n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    X_upsampled = df_upsampled.drop(columns=y.name)\n",
    "    y_upsampled = df_upsampled[y.name]\n",
    "\n",
    "    return X_upsampled, y_upsampled\n",
    "\n",
    "# Selected features\n",
    "selected_features = ['Disease_lymphoma', 'Txpostrelapse', 'Rbodymass']\n",
    "\n",
    "# Prepare the data\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "# Handle class imbalance\n",
    "X_balanced, y_balanced = balance_classes(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf, param_distributions=param_grid_rf, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters found for RF: \", random_search_rf.best_params_)\n",
    "print(\"Best cross-validation score for RF: \", random_search_rf.best_score_)\n",
    "\n",
    "# Evaluate the best RF model on the train and test set\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "y_rf_train_pred = best_rf.predict(X_train_scaled)\n",
    "y_rf_test_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Classification Report for RF (Test):\")\n",
    "print(classification_report(y_test, y_rf_test_pred))\n",
    "print(f\"Test Accuracy for RF: {accuracy_score(y_test, y_rf_test_pred):.4f}\")\n",
    "print(\"------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3dc07-53db-4bb4-884a-723f047c0d56",
   "metadata": {
    "id": "61a3dc07-53db-4bb4-884a-723f047c0d56"
   },
   "source": [
    "Hyperparameter tuning for the Random Forest model was performed using Randomized Search CV. The best parameters found were {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}, with a cross-validation score of approximately 0.651. The model was evaluated on the test set, yielding a classification report with precision, recall, and F1-scores for both classes. The test accuracy was 0.63, with balanced precision and recall for both classes.\n",
    "\n",
    "Overall, this approach demonstrated the importance of handling class imbalance and optimizing hyperparameters to improve model performance. Despite the relatively modest test accuracy, the Random Forest model showed balanced performance metrics, indicating its potential usefulness in predicting survival status with the selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb1718-582e-4809-8488-1dbff52935e5",
   "metadata": {
    "id": "d9cb1718-582e-4809-8488-1dbff52935e5",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.4. Model Evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283da0c-b53b-468f-b057-e7c922e6dea4",
   "metadata": {
    "id": "8694f5b2-edba-4a69-acd3-5848431a0340"
   },
   "outputs": [],
   "source": [
    "# Function to create the ANN model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(estimator, title, X, y, cv, n_jobs=-1):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(model, X_test, y_test, title):\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Data preparation\n",
    "selected_features = ['Disease_lymphoma', 'Txpostrelapse', 'Recipientage10', 'Rbodymass', 'Riskgroup']\n",
    "X = df[selected_features]\n",
    "y = df['survival_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "best_rf_params = {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}\n",
    "best_rf = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ANN\n",
    "ann = KerasClassifier(build_fn=create_model, epochs=120, batch_size=10, verbose=0)\n",
    "ann.fit(X_train_scaled, y_train)\n",
    "\n",
    "# SVM\n",
    "best_svm_params = {'kernel': 'linear', 'C': 100, 'gamma': 1, 'probability': True}\n",
    "best_svm = SVC(**best_svm_params)\n",
    "best_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# KNN\n",
    "best_knn_params = {'weights': 'distance', 'n_neighbors': 7, 'metric': 'euclidean'}\n",
    "best_knn = KNeighborsClassifier(**best_knn_params)\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curve(best_rf, \"Learning Curve (RF)\", X_train_scaled, y_train, cv=skf)\n",
    "plot_learning_curve(ann, \"Learning Curve (ANN)\", X_train_scaled, y_train, cv=skf)\n",
    "plot_learning_curve(best_svm, \"Learning Curve (SVM)\", X_train_scaled, y_train, cv=skf)\n",
    "plot_learning_curve(best_knn, \"Learning Curve (KNN)\", X_train_scaled, y_train, cv=skf)\n",
    "\n",
    "# Plot ROC curves\n",
    "plot_roc_curve(best_rf, X_test_scaled, y_test, \"ROC Curve (RF)\")\n",
    "plot_roc_curve(ann, X_test_scaled, y_test, \"ROC Curve (ANN)\")\n",
    "plot_roc_curve(best_svm, X_test_scaled, y_test, \"ROC Curve (SVM)\")\n",
    "plot_roc_curve(best_knn, X_test_scaled, y_test, \"ROC Curve (KNN)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eb8ca-c602-4de5-b9b1-454a17383c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics data\n",
    "models = [\"DT\", \"RF\", \"KNN\", \"SVM\", \"ANN\", \"NB\"]\n",
    "accuracy = [0.5294, 0.6316, 0.6053, 0.5789, 0.7020, 0.6471]\n",
    "precision_class_0 = [0.60, 0.60, 0.57, 0.55, 0.60, 0.61]\n",
    "precision_class_1 = [0.47, 0.67, 0.65, 0.61, 0.47, 1.00]\n",
    "recall_class_0 = [0.47, 0.67, 0.67, 0.61, 0.47, 1.00]\n",
    "recall_class_1 = [0.60, 0.60, 0.55, 0.55, 0.60, 0.20]\n",
    "f1_class_0 = [0.53, 0.63, 0.62, 0.58, 0.53, 0.76]\n",
    "f1_class_1 = [0.53, 0.63, 0.59, 0.58, 0.53, 0.33]\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "data = {\n",
    "    \"Model\": models * 2,\n",
    "    \"Class\": [\"Class 0\"] * len(models) + [\"Class 1\"] * len(models),\n",
    "    \"Accuracy\": accuracy + accuracy,\n",
    "    \"Precision\": precision_class_0 + precision_class_1,\n",
    "    \"Recall\": recall_class_0 + recall_class_1,\n",
    "    \"F1 Score\": f1_class_0 + f1_class_1\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.melt(id_vars=[\"Model\", \"Class\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Plot the bar plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=\"Model\", y=\"Score\", hue=\"Metric\", data=df)\n",
    "plt.title(\"Comparison of Performance Metrics for Different Models\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cfa83-2f71-4446-a11b-6c0b6390a07b",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.4.1 Comparison Between Enhanced Models and Previous Models\n",
    "\n",
    "**Decision Tree (DT)**\n",
    "\n",
    "**Previous Results:**\n",
    "\n",
    "Precision (Class 0/1): 0.64/0.58\n",
    "Recall (Class 0/1): 0.74/0.47\n",
    "F1-Score (Class 0/1): 0.68/0.52\n",
    "Accuracy: 0.53\n",
    "Training Accuracy: 0.5900\n",
    "Testing Accuracy: 0.5294\n",
    "**Observation:**\n",
    "\n",
    "The Decision Tree model showed a decent training accuracy but underperformed on the test set, indicating overfitting.\n",
    "##### Random Forest (RF)\n",
    "**Previous Results:**\n",
    "Precision (Class 0/1): 0.60/0.50\n",
    "Recall (Class 0/1): 0.63/0.47\n",
    "F1-Score (Class 0/1): 0.62/0.48\n",
    "Accuracy: 0.56\n",
    "Training Accuracy: 0.5974\n",
    "Testing Accuracy: 0.5588\n",
    "**Enhanced Results:**\n",
    "Precision (Class 0/1): 0.60/0.67\n",
    "Recall (Class 0/1): 0.67/0.60\n",
    "F1-Score (Class 0/1): 0.63/0.63\n",
    "Accuracy: 0.63\n",
    "Best Cross-Validation Score: 0.6514\n",
    "Testing Accuracy: 0.6316\n",
    "**Observation:**\n",
    "The enhanced Random Forest model showed significant improvement in both precision and recall, leading to better overall accuracy. The increased cross-validation score suggests better generalization.\n",
    "\n",
    "##### K-Nearest Neighbors (KNN)\n",
    "**Previous Results:**\n",
    "Precision (Class 0/1): 0.58/0.45\n",
    "Recall (Class 0/1): 0.37/0.67\n",
    "F1-Score (Class 0/1): 0.45/0.54\n",
    "Accuracy: 0.50\n",
    "Training Accuracy: 0.5903\n",
    "Testing Accuracy: 0.5000\n",
    "**Enhanced Results:**\n",
    "Precision (Class 0/1): 0.57/0.65\n",
    "Recall (Class 0/1): 0.67/0.55\n",
    "F1-Score (Class 0/1): 0.62/0.59\n",
    "Accuracy: 0.61\n",
    "Best Cross-Validation Score: 0.6248\n",
    "Testing Accuracy: 0.6053\n",
    "**Observation:**\n",
    "The enhanced KNN model shows a considerable improvement in both precision and recall for both classes. The increased testing accuracy indicates better model performance and reduced overfitting.\n",
    "\n",
    "##### Support Vector Machine (SVM)\n",
    "**Previous Results**:\n",
    "Precision (Class 0/1): 0.50/0.39\n",
    "Recall (Class 0/1): 0.42/0.47\n",
    "F1-Score (Class 0/1): 0.46/0.42\n",
    "Accuracy: 0.44\n",
    "Training Accuracy: 0.5900\n",
    "Testing Accuracy: 0.4412\n",
    "**Enhanced Results:**\n",
    "Precision (Class 0/1): 0.55/0.61\n",
    "Recall (Class 0/1): 0.61/0.55\n",
    "F1-Score (Class 0/1): 0.58/0.58\n",
    "Accuracy: 0.58\n",
    "Best Cross-Validation Score: 0.6123\n",
    "Testing Accuracy: 0.5789\n",
    "**Observation:**\n",
    "The enhanced SVM model shows significant improvement in precision and recall for both classes, indicating better model performance and reduced overfitting.\n",
    "\n",
    "##### Artificial Neural Network (ANN)\n",
    "**Previous Results:**\n",
    "Precision (Class 0/1): 0.50/0.39\n",
    "Recall (Class 0/1): 0.42/0.47\n",
    "F1-Score (Class 0/1): 0.46/0.42\n",
    "Accuracy: 0.44\n",
    "Training Accuracy: 0.7482\n",
    "Testing Accuracy: 0.7020\n",
    "**Enhanced Results:**\n",
    "Precision (Class 0/1): 0.60/0.47\n",
    "Recall (Class 0/1): 0.47/0.60\n",
    "F1-Score (Class 0/1): 0.53/0.53\n",
    "Accuracy: 0.53\n",
    "Training Accuracy: 0.7482\n",
    "Testing Accuracy: 0.7020\n",
    "\n",
    "**Observation:**\n",
    "The enhanced ANN model also showed improved results, particularly in balancing the precision and recall for both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de55f12-f0df-4a5d-82d1-0ffddd2fb288",
   "metadata": {},
   "source": [
    "#### 2.4.2. Model Selection\n",
    "We will be choosing the best model ensuring a high recall which means most true survivors are identified, allowing for necessary interventions. Additionally, high precision ensures those identified as survivors are truly likely to survive, balancing the overall effectiveness of the model. The learning curves were utilized to evaluate the models' performance and stability.\n",
    "\n",
    "**Model Performance Metrics**\n",
    "\n",
    "\n",
    "**Decision Tree (DT):**\n",
    "* Precision (Class 0/1): 0.60 / 0.47\n",
    "* Recall (Class 0/1): 0.47 / 0.60\n",
    "* F1-Score (Class 0/1): 0.53 / 0.53\n",
    "* Accuracy: 0.53\n",
    "\n",
    "**Observation for Decision Tree (DT):**\n",
    "* The Decision Tree model exhibits balanced F1-scores for both classes (0.53 for Class 0 and Class 1).\n",
    "* Precision and recall are inversely related for the two classes, with Class 0 showing higher precision (0.60) and lower recall (0.47), while Class 1 shows the opposite trend.\n",
    "* The overall accuracy is 0.53, which is relatively low, indicating that the model does not perform well in generalizing to new data.\n",
    "* The training accuracy is 0.5900, which is higher than the testing accuracy (0.5294), suggesting potential overfitting.\n",
    "\n",
    "**Justification for Eliminating Decision Tree (DT):**\n",
    "* Decision Trees are prone to overfitting, especially with limited and imbalanced datasets, as they can easily fit to noise and specific patterns in the training data.\n",
    "* The low testing accuracy indicates that the model does not generalize well to unseen data, which is crucial for predictive performance in medical applications.\n",
    "* The balanced F1-scores and the inverse relationship between precision and recall for the two classes indicate that the model struggles to consistently identify both survivors and non-survivors accurately.\n",
    "* The moderate training accuracy further supports that the model might not be capturing the underlying patterns effectively, leading to poor performance on the test set.\n",
    "* Due to these reasons, the Decision Tree model is not considered a reliable candidate for predicting survival status and is eliminated from consideration.\n",
    "________________________________________________________________________________________________________________________________\n",
    "**Naive Bayes (NB):**\n",
    "* Precision (Class 0/1): 0.61 / 1.00\n",
    "* Recall (Class 0/1): 1.00 / 0.20\n",
    "* F1-Score (Class 0/1): 0.76 / 0.33\n",
    "* Accuracy: 0.65\n",
    "\n",
    "**Observation for Naive Bayes (NB):**\n",
    "* Naive Bayes shows a high recall for Class 0 (1.00), indicating that it correctly identifies all non-survivors.\n",
    "* However, it has a very low recall for Class 1 (0.20), meaning it misses a significant number of true survivors.\n",
    "* The precision for Class 1 is perfect (1.00), but this is misleading due to the low recall.\n",
    "* The overall F1-Score is unbalanced with 0.76 for Class 0 and only 0.33 for Class 1.\n",
    "* The accuracy is moderate at 0.65, indicating that while it performs well for non-survivors, it struggles significantly with identifying survivors.\n",
    "* This imbalance highlights that NB may not be suitable for this task due to its inability to accurately predict true survivors, despite having a decent overall accuracy.\n",
    "\n",
    "**Justification for Eliminating Naive Bayes (NB):**\n",
    "* The poor performance of Naive Bayes on this dataset can be attributed to the assumptions it makes. NB assumes that features are independent and that the distribution of each feature within a class is normally distributed. These assumptions often do not hold true in complex medical datasets where features can be correlated and distributions can be non-Gaussian.\n",
    "* Additionally, Naive Bayes is sensitive to class imbalance. In this dataset, the imbalance between the number of non-survivors and survivors may lead to skewed results where the model becomes biased towards predicting the majority class.\n",
    "* The significant disparity in F1-Scores between the two classes further indicates that the model is not balanced and performs poorly in predicting one of the classes (survivors).\n",
    "* Due to these limitations, Naive Bayes is not considered a reliable candidate for predicting survival status in this context and is eliminated from consideration.\n",
    "________________________________________________________________________________________________________________________________\n",
    "**Random Forest (Enhanced):**\n",
    "Precision (Class 0/1): 0.60 / 0.67\n",
    "Recall (Class 0/1): 0.67 / 0.60\n",
    "F1-Score (Class 0/1): 0.63 / 0.63\n",
    "Accuracy: 0.63\n",
    "\n",
    "**Artificial Neural Network (ANN):**\n",
    "Precision (Class 0/1): 0.60 / 0.47\n",
    "Recall (Class 0/1): 0.47 / 0.60\n",
    "F1-Score (Class 0/1): 0.53 / 0.53\n",
    "Accuracy: 0.53\n",
    "\n",
    "**Support Vector Machine (SVM):**\n",
    "Precision (Class 0/1): 0.55 / 0.61\n",
    "Recall (Class 0/1): 0.61 / 0.55\n",
    "F1-Score (Class 0/1): 0.58 / 0.58\n",
    "Accuracy: 0.58\n",
    "\n",
    "**K-Nearest Neighbors (KNN):**\n",
    "Precision (Class 0/1): 0.57 / 0.65\n",
    "Recall (Class 0/1): 0.67 / 0.55\n",
    "F1-Score (Class 0/1): 0.62 / 0.59\n",
    "Accuracy: 0.61\n",
    "Observations\n",
    "_________________________________________________________________________________________________________________________________\n",
    "**Random Forest:**\n",
    "High Recall (Class 0): 0.67\n",
    "High Precision (Class 1): 0.67\n",
    "Balanced F1-Score: 0.63 for both classes\n",
    "\n",
    "**Artificial Neural Network (ANN):**\n",
    "**Lower Recall and Precision compared to RF**\n",
    "Balanced F1-Score: 0.53 for both classes\n",
    "\n",
    "**Support Vector Machine (SVM):**\n",
    "High Recall (Class 0): 0.61\n",
    "High Precision (Class 1): 0.61\n",
    "Balanced F1-Score: 0.58 for both classes\n",
    "K-Nearest Neighbors (KNN):\n",
    "High Recall (Class 0): 0.67\n",
    "High Precision (Class 1): 0.65\n",
    "Balanced F1-Score: 0.62 / 0.59\n",
    "\n",
    "#### Best Model Selection\n",
    "\n",
    "**Considering both precision and recall:**\n",
    "Support Vector Machine (SVM) shows a good balance of precision and recall across both classes, with F1-scores of 0.58 for both classes and stability indicated by the learning curve.\n",
    "Random Forest (RF) also performs well with balanced precision and recall, but slightly lower stability as indicated by the learning curve.\n",
    "K-Nearest Neighbors (KNN) has good metrics but less stability compared to SVM.\n",
    "Artificial Neural Network (ANN) shows lower precision and recall metrics compared to RF, SVM, and KNN.\n",
    "\n",
    "**Conclusion:**\n",
    "**Support Vector Machine (SVM)** is the best model based on the analysis of precision and recall combined with learning curve stability. It provides balanced F1-scores and robust performance across both classes, making it the most reliable model for predicting survival status in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71e39d-3f93-4baf-b6b4-1e380676e497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.5. Conclusion for the Second Approach\n",
    "This approach aimed to predict survival status using various machine learning models, focusing on handling class imbalance and optimizing performance. Initially, models included post-transplant features, resulting in high accuracy due to the richness of the data. Removing these features significantly dropped accuracy, highlighting their importance.\n",
    "\n",
    "Feature reduction techniques were applied to select relevant predictors, simplifying models and reducing overfitting. The ANN model notably improved with added complexity, achieving better performance. However, maintaining high accuracy was challenging due to the reduced feature set and limited data.\n",
    "\n",
    "The Support Vector Machine (SVM) model emerged as the best performer based on precision, recall, and stability as indicated by the learning curves. It balanced precision and recall effectively, making it the most reliable for this task.\n",
    "\n",
    "In summary, this approach demonstrated the importance of feature selection, class imbalance handling, and model tuning. Despite challenges, the use of advanced techniques allowed for reasonable predictive performance, underscoring the need for comprehensive data and sophisticated models in medical predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b8295",
   "metadata": {
    "id": "495b8295",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# III.Conclusion on the Overall Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f4228-3b1b-4a87-b0ed-e5e90f60c549",
   "metadata": {},
   "source": [
    " In this comprehensive study, we aimed to predict the survival status of patients using various machine learning models, including Decision Tree, Random Forest, K-Nearest Neighbors, Support Vector Machine, and Artificial Neural Networks. The approach was methodical, starting with feature selection, handling class imbalances, and optimizing model performance through hyperparameter tuning.\n",
    "\n",
    "Key findings include:\n",
    "\n",
    "* **Feature Selection and Reduction:** The initial model included post-transplant features, which significantly contributed to high accuracy. Removing these features led to a drop in performance, highlighting their predictive power. Employing feature reduction techniques helped simplify the models and reduce overfitting.\n",
    "\n",
    "* **Class Imbalance Handling:** Techniques like resampling were crucial in balancing the classes, ensuring that the models did not favor the majority class and performed well across all metrics.\n",
    "\n",
    "* **Model Optimization:** Hyperparameter tuning and cross-validation were vital in refining the models. The Random Forest model, in particular, showed the best balance between precision and recall, making it the most reliable model for predicting survival status in this dataset.\n",
    "\n",
    "* **Model Performance:** Despite the reduced feature set and limited data, the optimized models demonstrated reasonable performance. The ANN model benefited from increased complexity, achieving notable accuracy improvements.\n",
    "\n",
    "In conclusion, this study underscores the importance of comprehensive data, sophisticated modeling techniques, and careful feature selection in medical predictions. While challenges remain, the advancements in handling class imbalance and optimizing model performance pave the way for more accurate and reliable predictive models in healthcare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
